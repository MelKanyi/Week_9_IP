{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moringa_Data_Science_Core_W9_Independent_Project_2020_Melissa_Kanyi_Python_notebook",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzd/dx1NuGOTrxRKSfCcc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelKanyi/Week_9_IP/blob/master/Moringa_Data_Science_Core_W9_Independent_Project_2020_Melissa_Kanyi_Python_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRYBCFueBG9q",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"yellow\"> **Defining the Question**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdcewutKFRZH",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"red\"> Specifying the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9MnQxqBNI7",
        "colab_type": "text"
      },
      "source": [
        "- Predict if a passenger survived the sinking of the Titanic or not.\n",
        "- Predict whether an email is spam or ham."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkaae9L0BaUV",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"red\"> Metric of Success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WulcunipBZDs",
        "colab_type": "text"
      },
      "source": [
        "* Since both projects are classification problems, we will use:\n",
        "     * Accuracy; threshold 85%\n",
        "* For target class imbalance we will use \n",
        "* (harmonic mean between the positive rate (precision) and the negative rate (Recall))\n",
        "     * F1 score; threhold 85%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1EMMMqvBgCv",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"red\"> Experimental Design Taken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVQ2FEYNBymo",
        "colab_type": "text"
      },
      "source": [
        " **Predicting survival in the titanic Disaster**\n",
        " * Loading the dataset\n",
        " * Exploratory Data Analysis\n",
        " * Visualization\n",
        " * Data Cleaning\n",
        " * Features Engineering\n",
        " * Modeling: K-Nearest Neighbors Classifier (KNN)\n",
        " * Hyperparameter Tuning\n",
        " * Optimization techinques for KNN \n",
        " * Recommendations\n",
        " * Challenging the model: Random Forest Classifier\n",
        " * Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hayAjVnUB_Mf",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"red\"> Appropriateness of the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP0YwCi5CFZc",
        "colab_type": "text"
      },
      "source": [
        "**Dataset 1 links:**\n",
        "* Train set: [link text](https://www.kaggle.com/c/titanic/download/train.csv)\n",
        "* Test set:[link text](https://www.kaggle.com/c/titanic/download/test.csv)\n",
        "\n",
        "The dataset contains the following fields:\n",
        "* Pclass Ticket class (: 1=upper, 2=middle, 3=lower)\n",
        "* Sex : Gender\n",
        "* Age : Age in years (fractional for babies)\n",
        "* Sibsp : Number of siblings and spouse. Sibling = brother, sister, stepbrother, stepsister.    Spouse = husband, wife (mistresses and fiancés were ignored)\n",
        "* Parch: Number of parents or children aboard the ship. Parent = mother, father. Child = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore parch=0 for them.\n",
        "* Ticket: Ticket number (a string of characters)\n",
        "* Fare: Passenger fare (dollars)\n",
        "* Cabin: Cabin number (a string of characters)\n",
        "* Embarked: Port of embarkation (S=Southampton, Q=Queenstown (now Cobh), C=Cherbourg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okdFgcgz3yzH",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"yellow\"> **Reading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsOG5538otUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "# Importing visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sklearn libraries for data preparartion and performance measures\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, normalize, Normalizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Algorithms\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YkhBrprqVOD",
        "colab_type": "code",
        "outputId": "dbb15821-365b-4c33-812b-4b909de35f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# Loading the train dataset\n",
        "data = pd.read_csv('train.csv')\n",
        "data  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 516
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNkQGKD746Ij",
        "colab_type": "code",
        "outputId": "a97a03ee-cbf9-4e81-a73b-f54cc0bf4ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# Loading the test dataset\n",
        "test = pd.read_csv('test.csv')\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  ... Cabin Embarked\n",
              "0            892       3  ...   NaN        Q\n",
              "1            893       3  ...   NaN        S\n",
              "2            894       2  ...   NaN        Q\n",
              "3            895       3  ...   NaN        S\n",
              "4            896       3  ...   NaN        S\n",
              "..           ...     ...  ...   ...      ...\n",
              "413         1305       3  ...   NaN        S\n",
              "414         1306       1  ...  C105        C\n",
              "415         1307       3  ...   NaN        S\n",
              "416         1308       3  ...   NaN        S\n",
              "417         1309       3  ...   NaN        C\n",
              "\n",
              "[418 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMCheEn_ITn",
        "colab_type": "text"
      },
      "source": [
        "> We will not be using the test dataset because it does not have out dependent variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVoj2g2HCyO0",
        "colab_type": "code",
        "outputId": "0fcce844-c7ff-4ecd-e6e0-45da94041da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# checking the top of the data\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 518
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6YzbPSjC8go",
        "colab_type": "code",
        "outputId": "b51c6146-f4d1-415d-c5a5-2daf41d98cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# checking the bottom of the data\n",
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.00</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.00</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...   Fare Cabin  Embarked\n",
              "886          887         0       2  ...  13.00   NaN         S\n",
              "887          888         1       1  ...  30.00   B42         S\n",
              "888          889         0       3  ...  23.45   NaN         S\n",
              "889          890         1       1  ...  30.00  C148         C\n",
              "890          891         0       3  ...   7.75   NaN         Q\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 519
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3clk4UbDDDww",
        "colab_type": "text"
      },
      "source": [
        "From the table above: \n",
        "\n",
        "1. We need to convert a lot of features into numeric ones later on, so that the machine learning algorithms can process them.\n",
        "\n",
        "2. Furthermore, we can see that the features have widely different ranges, that we will need to convert into roughly the same scale. \n",
        "\n",
        "3. We can also spot some more features, that contain missing values (NaN = not a number), that we need to deal with.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72aSKjxPDN9e",
        "colab_type": "code",
        "outputId": "3a6e0768-7781-4377-c44f-df434d2bddc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# view summary information of our dataset\n",
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            "PassengerId    891 non-null int64\n",
            "Survived       891 non-null int64\n",
            "Pclass         891 non-null int64\n",
            "Name           891 non-null object\n",
            "Sex            891 non-null object\n",
            "Age            714 non-null float64\n",
            "SibSp          891 non-null int64\n",
            "Parch          891 non-null int64\n",
            "Ticket         891 non-null object\n",
            "Fare           891 non-null float64\n",
            "Cabin          204 non-null object\n",
            "Embarked       889 non-null object\n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "235g2hMkDj6H",
        "colab_type": "code",
        "outputId": "4a99e59d-ddb7-4fa0-bc60-4cd6e4d23233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "# checking for unique values \n",
        "\n",
        "cols = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n",
        "\n",
        "for col in cols:\n",
        "  print(col)\n",
        "  print(data[col].unique())\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pclass\n",
            "[3 1 2]\n",
            "\n",
            "\n",
            "Sex\n",
            "['male' 'female']\n",
            "\n",
            "\n",
            "SibSp\n",
            "[1 0 3 4 2 5 8]\n",
            "\n",
            "\n",
            "Parch\n",
            "[0 1 2 5 3 4 6]\n",
            "\n",
            "\n",
            "Embarked\n",
            "['S' 'C' 'Q' nan]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajGsYisXDok8",
        "colab_type": "code",
        "outputId": "5f35ca25-c281-4592-fe0a-3963a643f808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# Statistical description of numerical columns\n",
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh4jlTbaD3JP",
        "colab_type": "text"
      },
      "source": [
        "Above we can see that 38% out of the dataset survived the Titanic.\n",
        "\n",
        "We can also see that the passenger ages range from 0.4 to 80.\n",
        "\n",
        "On top of that we can already detect some features, that contain missing values, like the ‘Age’ feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rTL6xk2Mr8Q",
        "colab_type": "text"
      },
      "source": [
        "* It is clear that people from the First class had higher chances of survival.\n",
        "* Pclass is therefore an important feature to predict survival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiFor-STL0-9",
        "colab_type": "text"
      },
      "source": [
        "* Survival chance of women are higher between 14 and 40\n",
        "* Men have a high probability of survival when they are between 18 and 30 years old.\n",
        "* In both generally infants have a little bit of higher chances of survival.\n",
        "* Certain ages hava increased odds of survival.\n",
        "* Creating age groups in our feature engineering may help to make every feature of the same scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cy7hwGa_ahx",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"yellow\"> **Data Cleaning** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0FAJvufii8l",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Cleaning the Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBtX8JuxVOj0",
        "colab_type": "code",
        "outputId": "e2b8f499-7fd5-4fd1-8e50-ba1bbc4d06f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# checking data types\n",
        "data.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Sex             object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Ticket          object\n",
              "Fare           float64\n",
              "Cabin           object\n",
              "Embarked        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9-5ZaHNVBeZ",
        "colab_type": "text"
      },
      "source": [
        "Which features are:\n",
        "\n",
        "1. **Categorical ?**\n",
        "- Survived\n",
        "- Sex\n",
        "- Embarked\n",
        "\n",
        "2. **Ordinal?**\n",
        "- Pclass.\n",
        "\n",
        "3. **Numerical?**\n",
        "- Age (Continuous)\n",
        "- Fare (Continuous)\n",
        "- SibSp (Discrete)\n",
        "- Parch (Discrete)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYOhIR7BVWhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the relevant data types to categorical\n",
        "\n",
        "# Creating a list of the numerical columns in the dataset.\n",
        "numeric = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "\n",
        "categoricals = ['Survived','Pclass','Sex','Embarked']\n",
        "\n",
        "objects = ['Name']\n",
        "\n",
        "for x in data.columns:\n",
        "   if x in numeric:\n",
        "       data[x]=pd.to_numeric(data[x])\n",
        "   elif x in categoricals:\n",
        "        data[x]=data[x].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCwTfzQeVbop",
        "colab_type": "code",
        "outputId": "865871f3-5f8e-4b57-a362-a755e3ec82ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "#Check if features are assigned the relevant data types\n",
        "data.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId       int64\n",
              "Survived       category\n",
              "Pclass         category\n",
              "Name             object\n",
              "Sex            category\n",
              "Age             float64\n",
              "SibSp             int64\n",
              "Parch             int64\n",
              "Ticket           object\n",
              "Fare            float64\n",
              "Cabin            object\n",
              "Embarked       category\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 526
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voN31qLb8xzC",
        "colab_type": "code",
        "outputId": "c4969c04-4e72-4c3c-e5b2-a527fb9e2bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# checking for missing values \n",
        "data.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    False\n",
              "Survived       False\n",
              "Pclass         False\n",
              "Name           False\n",
              "Sex            False\n",
              "Age             True\n",
              "SibSp          False\n",
              "Parch          False\n",
              "Ticket         False\n",
              "Fare           False\n",
              "Cabin           True\n",
              "Embarked        True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3fQ-OSD_ukt",
        "colab_type": "code",
        "outputId": "285581ef-d4f8-4596-ebf6-4ea77c88b829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcu-sAuerxf",
        "colab_type": "text"
      },
      "source": [
        "The Embarked feature has only 2 missing values, which can easily be filled by mode.\n",
        "\n",
        "It will be much more tricky, to deal with the ‘Age’ feature, which has 177 missing values.\n",
        "\n",
        "The ‘Cabin’ feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxT63ivxesmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replacing all missing values with the mean in the age column\n",
        "data['Age'].fillna((data['Age'].mean()), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_N0Cx4QPsEM",
        "colab_type": "code",
        "outputId": "4152a24b-9b8e-447b-8ef9-55d6f11c98bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# confirming changes\n",
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUHXekFUWShD",
        "colab_type": "text"
      },
      "source": [
        "The Embarked column has 2 missing values. It's best to fill them with the most common values in that column to maintain its frequency distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faH6_gdXf4y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace the null values in the Embarked column with the mode\n",
        "\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBJ_Fs0iP2vP",
        "colab_type": "code",
        "outputId": "e7301fd1-aa5f-4ed2-fbb8-46c007a8a182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# confirming changes\n",
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9V75CmDQRNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# column cabin containing categorical values \n",
        "# dropping the columns since it contains very many missing values\n",
        "data.drop('Cabin', axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY2Ve4q3QeWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping the unnecessary columns\n",
        "data.drop(['PassengerId', 'Ticket'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zortzdU9QUFp",
        "colab_type": "code",
        "outputId": "7a014074-9185-4f7b-f972-8e486520368d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# confirming changes\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass  ...     Fare Embarked\n",
              "0        0      3  ...   7.2500        S\n",
              "1        1      1  ...  71.2833        C\n",
              "2        1      3  ...   7.9250        S\n",
              "3        1      1  ...  53.1000        S\n",
              "4        0      3  ...   8.0500        S\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 535
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMuH9WAQg6Wt",
        "colab_type": "code",
        "outputId": "7649e279-4a7d-4ab9-a089-233f9f199b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# checking if the data set contains duplicates\n",
        "data.duplicated(subset = None, keep = 'first')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "886    False\n",
              "887    False\n",
              "888    False\n",
              "889    False\n",
              "890    False\n",
              "Length: 891, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 536
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWkpfXRoQ0aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# droping the duplicated values \n",
        "data.drop_duplicates(subset = None, keep = 'first', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxzkGqbnRFu0",
        "colab_type": "code",
        "outputId": "fa33b9ba-12fe-4120-d2a4-496edca5c70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# checking if the data set contains duplicates\n",
        "data.duplicated(subset = None, keep = 'first')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "886    False\n",
              "887    False\n",
              "888    False\n",
              "889    False\n",
              "890    False\n",
              "Length: 891, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 538
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0EkLR6ALJGN",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"yellow\"> **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXL6WDPeXYEO",
        "colab_type": "text"
      },
      "source": [
        "Plot a Correlation Matrix to establish the significance among features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWK3jjtSXSB3",
        "colab_type": "code",
        "outputId": "9cf30191-82b5-44b4-dd05-2aeb1ce96384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "corr = data.corr()\n",
        "\n",
        "ax = sns.heatmap(corr,square=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAD/CAYAAABhEBrvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEj2mOiISPaY6IhI9pjoiEj2/hd84XIvRRT/9AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ-G0nYyXhh-",
        "colab_type": "code",
        "outputId": "545d402e-b0fd-4587-aaf4-c83217973a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data.Survived.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    549\n",
              "1    342\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 540
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUEWv2Ckvokz",
        "colab_type": "code",
        "outputId": "9711d85b-f121-4fd6-f533-e507622845a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Using a bar chart from seaborn\n",
        "sns.set(style = 'whitegrid', context = 'notebook')\n",
        "sns.barplot(x='Pclass', y='Survived', data=data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f91d603f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 523
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEMCAYAAAAxoErWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACGKAkAgCFKAgBgiJIAABj6f2dI5QW25ZR+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TG2ODb9QGA9",
        "colab_type": "code",
        "outputId": "c329a780-2f69-40ad-cdfc-26c2a275b8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "\n",
        "sex = pd.DataFrame({'count': data.groupby(['Pclass','Sex']).size()}).reset_index()\n",
        "# sns.barplot(x = 'Pclass', y = 'count', hue = 'Sex', data = sex)\n",
        "g = sns.catplot(x = 'Sex', y = 'count',\n",
        "           col = 'Pclass', data = sex,\n",
        "           kind = 'bar', aspect = 0.5, height = 6)\n",
        "g.set_axis_labels('Gender', 'Number of passengers')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnwAAAGkCAYAAACraPiJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXQUdbrG8ac7G4QthIEkLCMSBaI5\nSEiQyyiLAWQ5DKAiAoJzQVxABcSwCJJAWBNQL2gQkQEVI4zosMuiouMKDggDGVSQVSAmZGHP3nX/\n4NhORggV0p1OKt/POXNOun5V9Xu74ss8qeqqthmGYQgAAACWZfd0AQAAAHAvAh8AAIDFEfgAAAAs\njsAHAABgcQQ+AAAAiyPwAQAAWByBD9q5c6c6duzo6TKACoF+AH5DP1iHt6cLgGtFR0crIyNDXl5e\nql69ujp27KipU6eqRo0ani6tzN555x39/e9/18GDB9W7d2/NnTvX0yWhgrNqP+Tn52vatGn65ptv\ndPbsWf3xj3/UuHHj1KlTJ0+XhgrMqv0gSTExMdqxY4cuX76s+vXra8SIEXrwwQc9XVaFwhk+C1q8\neLH27NmjNWvWKCUlRa+99pqnS3KJBg0aaNSoUXrggQc8XQoqESv2Q2FhoUJCQrRixQrt3r1bY8eO\n1dixY3Xy5ElPl4YKzor9IElPPPGEtm/fru+++06LFi3S//3f/yklJcXTZVUoBD4LCwoKUocOHXTo\n0CFJ0tmzZ/X888/r7rvvVtu2bTVq1KirbrdkyRJ17dpVERER6tWrlz766CPn2PHjxzVkyBBFRkaq\nXbt2Gjt2rCTJMAzNnj1b7du3V5s2bfTnP/9ZBw8edOn7uffee9W1a1cFBAS4dL+oGqzUD/7+/nrm\nmWfUuHFj2e123XPPPWrcuLH+/e9/u2wOWJuV+kGSbr31Vvn6+kqSbDabbDabTpw44dI5Kjsu6VpY\namqqPv/8c3Xr1k2SNGHCBPn7+2vTpk3y9/fXnj17rrpdkyZNlJycrPr162vLli0aP368tm3bpgYN\nGmjBggW666679Pbbb6ugoED79++XJH355ZfatWuXtm7dqlq1aunIkSOqVavWVfc/bdo0bdy48apj\nISEh2rBhgwvePVCclfshIyNDx44d0y233GLmUACW7Idp06ZpzZo1ys3N1W233cZHHP4Lgc+Cnnrq\nKXl5ealWrVrq1KmTnnzySaWnp+vzzz/Xzp07VadOHUnSnXfeedXte/bs6fy5V69eev3117Vv3z51\n7dpV3t7eOn36tNLT0xUcHKyoqChJkre3ty5duqQjR46oVatWCg0NvWZ906ZN07Rp01z3hoESWL0f\nCgoKFBMTo/vuu6/EeQDJ2v0wbdo0TZ06VXv27NG3337rPOOHKwh8FpSUlKQ//elPxZYdPHhQderU\ncTZzSdauXavly5fr1KlTkqTLly8rOztbkjR+/HgtWLBA/fv3V506dTRs2DD1799f7du318MPP6z4\n+HidOnVK9957ryZOnKiaNWu6/g0CpWDlfnA4HJowYYJ8fHw0depUl+4b1mTlfpAkLy8vRUVFaf36\n9Vq5cqUeeeQRl89RWRH4qojg4GCdO3dO58+fV+3ata+53qlTp/TCCy/ozTffVEREhLy8vNS3b1/n\neP369TVz5kxJ0q5duzRs2DC1bdtWN910kx555BE98sgjyszM1NixY7V06VLnZzj+U2xs7DVPyzds\n2FCbNm0q47sFSmaFfjAMQ1OmTFFGRobeeOMN+fj4lOYQAE5W6If/VlRUxGf4/guBr4po0KCBOnbs\nqOnTpys2Nlb+/v7au3ev2rZtW2y9nJwc2Ww2BQYGSpI++OAD54d6JWnz5s2KiIhQcHCw6tSpI5vN\nJrvdrn379skwDN12222qXr26fH19Zbdf/Z6g+Ph4xcfHl/o9FBYWqqioSA6HQ0VFRcrLy5OXl5e8\nvfnPGKVjhX6Ii4vT4cOHtXz5clWrVq3U2wO/quz9kJmZqR07dqhz586qVq2avv76a23atEkvvvhi\nKY+EtfH/lFVIYmKi5syZo549e6qgoEDt2rX7XUPfcsstGj58uAYOHCibzaZ+/fqpTZs2zvH9+/dr\n9uzZunjxourVq6cpU6aoSZMmOnnypGbPnq2TJ0/K19dXd999tx599FGX1v/aa6/p1Vdfdb5ev369\nnn76aT3zzDMunQdVQ2Xuh1OnTulvf/ubc9+/mj59uvr06eOyeVB1VOZ+sNlsWrlypeLi4uRwONSo\nUSNNnjxZXbp0cdkcVmAzDMPwdBEAAABwH57DBwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiLBv4DMNQ\nXl6euCcFoB+AX9ELqKosG/jy8/OVkpKi/Px8T5cCeBz9AFxBL6CqsmzgAwAAwBUEPgAAAIsj8AEA\nAFgcgQ8AAMDiCHwAAAAWR+ADAACwOAIfAACAxRH4AAAALI7ABwAAYHHe5TXRqFGjdPLkSdntdvn7\n+2vq1KkKCwtTdHS0fH195efnJ0mKiYlRhw4dJEl79+5VbGys8vLy1KhRI82bN0/16tUrr5IBAAAs\nodwCX0JCgmrVqiVJ+vjjjzV58mStWbNGkrRw4UI1b9682PoOh0Pjx4/XnDlzFBUVpUWLFmn+/Pma\nM2dOeZUMAABgCeV2SffXsCdJFy9elM1mK3H9lJQU+fn5KSoqSpI0cOBAbdmyxa01AgAAWFG5neGT\npClTpuirr76SYRhaunSpc3lMTIwMw1BkZKTGjRun2rVrKzU1VQ0bNnSuExgYKIfDobNnzyogIKA8\nywYAAKjUyjXwzZo1S5K0du1aJSYm6o033lBycrJCQkKUn5+vWbNmKT4+XvPnz3fZnCkpKS7bF1BR\nREZG3tB29AOshl4AflNSP5Rr4PtVv379FBsbq+zsbIWEhEiSfH19NXjwYI0cOVKSFBISotOnTzu3\nycrKkt1uL/XZvfDwcOcNIUBVRz8AV9ALqGrK5TN8ly5dUmpqqvP19u3bVadOHfn5+enChQuSJMMw\n9OGHHyosLEzSlWbMzc3Vrl27JEmrVq1Sjx49yqNcAAAASymXM3w5OTkaM2aMcnJyZLfbVadOHS1e\nvFiZmZl65plnVFRUJIfDodDQUMXFxUmS7Ha7EhMTFRcXV+yxLAAAwFochQWye/t4uowKrazHyGYY\nhuHCeiqMvLw8paSkcNoeEP0A/IpeqLh2J47wdAkVWuSEpddfqQR80wYAAIDFEfgAAAAsjsAHAABg\ncQQ+AAAAiyPwAQAAWByBDwAAwOIIfAAAABZH4AMAALA4Ah8AAIDFEfgAAAAsjsAHAABgcQQ+AAAA\niyPwAQAAWByBDwAAwOIIfAAAABZH4AMAALA4Ah8AAIDFEfgAAAAsjsAHAABgcQQ+AAAAiyPwAQAA\nWByBDwAAwOIIfAAAABZH4AMAALA4Ah8AAIDFEfgAAAAsjsAHAABgcQQ+AAAAiyPwAQAAWByBDwAA\nwOIIfAAAABZH4AMAALA4Ah8AAIDFEfgAAAAsjsAHAABgcQQ+AAAAiyPwAQAAWByBDwAAwOIIfAAA\nABZH4AMAALA47/KaaNSoUTp58qTsdrv8/f01depUhYWF6ejRo5o0aZLOnj2rgIAAJSQkqGnTppJU\n4hgAAADMKbczfAkJCVq/fr3Wrl2r4cOHa/LkyZKkuLg4DR48WFu3btXgwYMVGxvr3KakMQAAAJhT\nboGvVq1azp8vXrwom82mzMxMHThwQL1795Yk9e7dWwcOHFBWVlaJYwAAADCv3C7pStKUKVP01Vdf\nyTAMLV26VKmpqQoKCpKXl5ckycvLSw0aNFBqaqoMw7jmWGBgoOk5U1JS3PJeAE+KjIy8oe3oB1gN\nvWANN/p7rGp2795d4nhJx7FcA9+sWbMkSWvXrlViYqLGjBnj9jnDw8Pl5+fn9nmAyoB+AK6gF1AZ\nlSUYe+Qu3X79+mnnzp0KDg5WWlqaioqKJElFRUVKT09XSEiIQkJCrjkGAAAA88ol8F26dEmpqanO\n19u3b1edOnVUr149hYWFaePGjZKkjRs3KiwsTIGBgSWOAQAAwLxyuaSbk5OjMWPGKCcnR3a7XXXq\n1NHixYtls9k0bdo0TZo0SYsWLVLt2rWVkJDg3K6kMQAAAJhTLoHvD3/4g957772rjoWGhmr16tWl\nHgMAAIA5fNMGAACAxRH4AAAALI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAWR+ADAACw\nOAIfAACAxRH4AAAALI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAWR+ADAACwOAIfAACA\nxRH4AAAALI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAWR+ADAACwOAIfAACAxRH4AAAA\nLI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAWR+ADAACwOAIfAACAxRH4AAAALI7ABwAA\nYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAW510ek2RnZ2vChAk6ceKEfH19ddNNNyk+Pl6BgYFq\n0aKFmjdvLrv9SvZMTExUixYtJEnbt29XYmKiioqKdPvtt2vOnDmqXr16eZQMAABgGeVyhs9ms2nE\niBHaunWrNmzYoCZNmmj+/PnO8VWrVmndunVat26dM+xdunRJU6dO1eLFi/XRRx+pRo0a+utf/1oe\n5QIAAFjKDQW+3Nxc5efnm14/ICBA7dq1c75u3bq1Tp8+XeI2n3/+ucLDw9W0aVNJ0sCBA7V58+Yb\nKRcAAKBKMxX4EhIStG/fPknSZ599pjvvvFNt27bV9u3bSz2hw+HQypUrFR0d7Vw2dOhQ9e3bVy++\n+KIzSKampqphw4bOdRo2bKjU1NRSzwcAAFDVmfoM34YNGzR69GhJUlJSkubNm6datWppzpw5xYKb\nGTNmzJC/v7+GDBki6UqADAkJ0cWLFzV+/HglJSXp2WefLeXbuLaUlBSX7QuoKCIjI29oO/oBVkMv\nWMON/h6rmt27d5c4XtJxNBX4cnJyVL16dWVnZ+vnn39W9+7dJUmnTp0qRZlXzhQeP35cixcvdt6k\nERISIkmqWbOmHnzwQS1fvty5fOfOnc5tT58+7Vy3NMLDw+Xn51fq7QAroh+AK+gFVEZlCcamLuk2\nbdpU69evV3Jysu666y5JUlZWlqpVq2Z6opdeekkpKSlKSkqSr6+vJOncuXPKzc2VJBUWFmrr1q0K\nCwuTJHXo0EH79+/XsWPHJF25saNnz56m5wMAAMAVps7wxcXFafbs2fLx8dGsWbMkSV9++aUz/F3P\noUOH9Prrr6tp06YaOHCgJKlx48YaMWKEYmNjZbPZVFhYqIiICI0ZM0bSlTN+8fHxeuKJJ+RwOBQW\nFqYpU6bcyHsEAACo0q4b+IqKinTw4EG99dZbxU5/9+nTR3369DE1ya233qoff/zxqmMbNmy45nZd\nu3ZV165dTc0BAACAq7vuJV0vLy/NnTuXzzoAAABUUqY+w3fPPffc0CNYAAAA4HmmPsOXl5en0aNH\nKyIiQsHBwbLZbM6xxMREtxUHAACAsjMV+Jo3b67mzZu7uxYAAAC4ganA9/TTT7u7DgAAALiJqcAn\nSV999ZU2bdqkrKwsLV68WPv379fFixfVvn17d9YHAACAMjJ108aKFSs0bdo0NW3aVP/85z8lSdWq\nVdOCBQvcWhwAAADKzlTge+utt7R8+XI9/vjjzq9Ea9asmY4ePerW4gAAAFB2pgLfpUuXnN9j++sd\nuoWFhfLx8XFfZQAAAHAJU4Gvbdu2WrJkSbFlb7/9ttq1a+eWogAAAOA6pm7aeOGFF/Tkk09q9erV\nunTpkrp3764aNWro9ddfd3d9AAAAKCNTga9Bgwb64IMPtG/fPp0+fVohISFq1aqV8/N8AAAAqLhM\nP5bFZrPpjjvu0B133OHOegAAAOBipgJfp06din2d2q98fX0VFBSke++9V4MGDZK3t+n8CAAAgHJi\nKqENHTpU69ev19ChQxUSEqLU1FQlJyerR48eqlOnjpYvX67U1FRNmDDB3fUCAACglEwFvjVr1mjZ\nsmUKCgpyLuvYsaOGDx+uTZs2qV27dho2bBiBDwAAoAIyddfFmTNnVKNGjWLLqlevrvT0dEnSzTff\nrPPnz7u+OgAAAJSZqTN899xzj0aOHKmRI0cqKChIaWlpev3113XPPfdIkvbs2aPGjRu7tVAAAADc\nGFOBLz4+Xq+88opiY2OVnp6u+vXrq2fPnnrqqackSU2aNOGZfAAAABWUqcDn5+enmJgYxcTEXHW8\nfv36Li0KAAAArmP6OSpHjhzRDz/8oMuXLxdb3r9/f5cXBQAAANcxFfgWL16spKQktWzZUtWqVXMu\nt9lsBD4AAIAKzlTge+utt7R69Wq1bNnS3fUAAADAxUw9lqVatWpq1qyZu2sBAACAG5gKfGPGjNHM\nmTOVnp4uh8NR7H8AAACo2Exd0p00aZIkafXq1c5lhmHIZrPp+++/d09lAAAAcAlTge+TTz5xdx0A\nAABwE1OBr1GjRpIkh8OhjIwMNWjQwK1FAQAAwHVMfYbv/Pnzeu6559SqVSvde++9kq6c9Xv55Zfd\nWhwAAADKzlTgi4uLU82aNbV9+3b5+PhIkiIiIrR582a3FgcAAICyM3VJ95tvvtEXX3whHx8f2Ww2\nSVJgYKAyMzPdWhwAAADKztQZvlq1aik7O7vYstOnT/MdugAAAJWAqcD34IMPavTo0dqxY4ccDof2\n7NmjiRMnauDAge6uDwAAAGVk6pLuY489Jj8/P8XHx6uwsFCTJ0/WQw89pL/85S/urg8AAABlZCrw\n2Ww2/eUvfyHgAQAAVEKmLunu2LFDP//8syTpzJkzmjhxop5//nmdOXPGrcUBAACg7EwFvunTp8vL\ny0uSNHfuXBUWFspms2nq1KluLQ4AAABlZ+qSblpamho2bKjCwkJ9+eWXzufxdejQwd31AQAAoIxM\nBb6aNWsqIyNDhw4dUmhoqGrUqKH8/HwVFha6uz4AAACUkanAN2TIEPXv318FBQWaPHmyJOm7775T\ns2bN3FocAAAAys5U4Hv88cfVrVs3eXl56Y9//KMkKSgoSDNnzjQ1SXZ2tiZMmKATJ07I19dXN910\nk+Lj4xUYGKi9e/cqNjZWeXl5atSokebNm6d69epJUoljAAAAMMfUTRuSdPPNNzvD3o4dO3TmzBm1\naNHC1LY2m00jRozQ1q1btWHDBjVp0kTz58+Xw+HQ+PHjFRsbq61btyoqKkrz58+XpBLHAAAAYJ6p\nwDdkyBDt3r1bkrRkyRKNGzdOzz33nBYvXmxqkoCAALVr1875unXr1jp9+rRSUlLk5+enqKgoSdLA\ngQO1ZcsWSSpxDAAAAOaZuqR76NAhtW7dWpK0evVqvf3226pRo4YGDRqkJ598slQTOhwOrVy5UtHR\n0UpNTVXDhg2dY4GBgXI4HDp79myJYwEBAabnS0lJKVV9QGUQGRl5Q9vRD7AaesEabvT3WNX8evLt\nWko6jqYCn8PhkM1m04kTJ2QYhm655RZJ0rlz50pR5hUzZsyQv7+/hgwZoo8++qjU25dWeHi4/Pz8\n3D4PUBnQD8AV9AIqo7IEY1OBLzIyUvHx8Tpz5oy6desmSTpx4oTq1q1bqskSEhJ0/PhxLV68WHa7\nXSEhITp9+rRzPCsrS3a7XQEBASWOAQAAwDxTn+GbM2eOateurRYtWujpp5+WJB05ckSPPPKI6Yle\neuklpaSkKCkpSb6+vpKu/IWVm5urXbt2SZJWrVqlHj16XHcMAAAA5pk6w1e3bl2NGzeu2LLOnTub\nnuTQoUN6/fXX1bRpUw0cOFCS1LhxYyUlJSkxMVFxcXHFHr0iSXa7/ZpjAAAAMM9U4JOk77//Xrt2\n7VJ2drYMw3AuHzNmzHW3vfXWW/Xjjz9edaxNmzbasGFDqccAAABgjqlLun/72980aNAg7dixQ2+8\n8YYOHjyo5cuX68SJE+6uDwAAAGVkKvAtXbpUS5cuVVJSkqpVq6akpCQtWLBA3t6mTxACAADAQ0wF\nvszMTOcDkO12uxwOhzp16qRPP/3UrcUBAACg7EydogsODtbJkyfVuHFjNW3aVJ988onq1q0rHx8f\nd9cHAACAMjIV+EaMGKHDhw+rcePGGjVqlMaMGaOCggJNmTLF3fUBAACgjEwFvvvvv9/5c6dOnfTt\nt9+qoKBANWrUcFthAAAAcA3Td12cP39en332mdLT09WgQYNSPYcPAAAAnmPqpo1vvvlG0dHRWrFi\nhfbv36933nlH0dHR+uabb9xdHwAAAMrI1Bm+GTNmKD4+Xr169XIu27x5s6ZPn64tW7a4rTgAAACU\nnakzfOnp6erevXuxZd26dVNGRoZbigIAAIDrmAp8ffv2VXJycrFlK1euVL9+/dxSFAAAAFzH1CXd\nAwcOaNWqVVq6dKmCgoKUlpamrKwstWrVSg8//LBzvf8OhQAAAPA8U4FvwIABGjBggLtrAQAAgBuY\nCnz33Xefu+sAAACAm5j6DB8AAAAqLwIfAACAxRH4AAAALO6age8/b9J49dVXy6UYAAAAuN41A9+x\nY8eUl5cnSVq2bFm5FQQAAADXuuZdul26dFH37t3VqFEj5eXlFXve3n/i2XsAAAAV2zUD35w5c7Rr\n1y6dOnVK+/fvV//+/cuzLgAAALhIic/hi4qKUlRUlAoKCngWHwAAQCVl6sHL/fv3186dO7V27Vql\np6erQYMG6tu3r/7nf/7H3fUBAACgjEw9lmX16tUaO3as6tevr27duqlBgwZ67rnn9N5777m7PgAA\nAJSRqTN8S5cu1fLly9WyZUvnsp49e2r06NF8xy4AAEAFZ+oM39mzZxUaGlpsWbNmzXTu3Dm3FAUA\nAADXMRX42rRpo7lz5yonJ0eSdPnyZSUmJioiIsKtxQEAAKDsTF3SnT59up599llFRUWpTp06Onfu\nnCIiIvTiiy+6uz4AAACUkanA16BBAyUnJ+uXX35x3qUbHBzs7toAAADgAqYC36+Cg4MJegAAAJWM\nqc/wAQAAoPIi8AEAAFjcdQOfw+HQN998o/z8/PKoBwAAAC523cBnt9s1atQo+fr6lkc9AAAAcDFT\nl3Tbtm2rvXv3ursWAAAAuIGpu3QbNmyoxx57TF26dFFwcLBsNptzbMyYMW4rDgAAAGVnKvDl5eWp\na9eukqS0tDS3FgQAAADXMhX45syZ4+46AAAA4CamH7x8+PBhbdmyRZmZmYqNjdWRI0eUn5+vli1b\nurM+AAAAlJGpmzY2b96shx9+WGlpaVq7dq0k6dKlS5o7d67piRISEhQdHa0WLVro4MGDzuXR0dHq\n0aOH+vbtq759++qLL75wju3du1d9+vRR9+7dNXz4cGVmZpqeDwAAAFeYCnwLFy7Um2++qfj4eHl5\neUmSWrZsqR9++MH0RF26dFFycrIaNWp01f2vW7dO69atU4cOHSRdef7f+PHjFRsbq61btyoqKkrz\n5883PR8AAACuMBX4srKy1KJFC0ly3qFrs9mK3a17PVFRUQoJCTG9fkpKivz8/BQVFSVJGjhwoLZs\n2WJ6ewAAAFxhKvDdfvvtWrduXbFlmzZtUqtWrVxSRExMjP785z9r2rRpOn/+vCQpNTVVDRs2dK4T\nGBgoh8Ohs2fPumROAACAqsLUTRtTpkzRo48+qvfff1+XL1/Wo48+qqNHj2rZsmVlLiA5OVkhISHK\nz8/XrFmzFB8f79JLtykpKS7bF1BRREZG3tB29AOshl6whhv9PVY1u3fvLnG8pONoKvCFhoZq8+bN\n+vTTT9W5c2eFhISoc+fOqlGjRukqvYpfL/P6+vpq8ODBGjlypHP56dOnnetlZWXJbrcrICCgVPsP\nDw+Xn59fmesErIB+AK6gF1AZlSUYm7qkK0nVq1dXZGSk7rzzTkVFRbkk7F2+fFkXLlyQJBmGoQ8/\n/FBhYWGSrjRjbm6udu3aJUlatWqVevToUeY5AQAAqhpTZ/hOnz6tmJgY/etf/1Lt2rV1/vx53XHH\nHZo3b95V77q9mpkzZ2rbtm3KyMjQsGHDFBAQoMWLF+uZZ55RUVGRHA6HQkNDFRcXJ0my2+1KTExU\nXFyc8vLy1KhRI82bN+/G3ykAAEAVZTMMw7jeSkOHDlXLli317LPPyt/fX5cuXdKCBQv0/fffa8WK\nFeVRZ6nl5eUpJSWF0/aA6AfgV/RCxbU7cYSnS6jQIicsLdP2ps7w/fvf/9ayZcvk4+MjSapRo4Zi\nYmLUrl27Mk0OAAAA9zP1Gb7WrVtr3759xZalpKQoIiLCLUUBAOBp+QVFni6hwuMYVR7XPMO3YMEC\n589NmjTR448/rs6dOys4OFi//PKL/vGPf6h3797lUiQAAOXN18dLgycke7qMCu3dxIc9XQJMumbg\n++WXX4q9vvfeeyVdeTyKr6+vunXrpry8PPdWBwAAgDK7ZuCbM2dOedYBAAAANzF104Yk5eTk6Pjx\n47p8+XKx5W3atHF5UQAAAHAdU4Fv7dq1io+Pl4+Pj6pVq+ZcbrPZ9Nlnn7mrNgAAALiAqcA3b948\nvfLKK7rrrrvcXQ8AAABczNRjWXx8fHTnnXe6uxYAAAC4ganAN2bMGM2dO1dZWVnurgcAAAAuZuqS\nbtOmTbVw4UK9++67zmWGYchms+n77793W3EAAAAoO1OBb8KECerbt6969epV7KYNAAAAVHymAt/Z\ns2c1ZswY2Ww2d9cDAAAAFzP1Gb77779f69atc3ctAAAAcANTZ/j27dun5ORkvfbaa/rDH/5QbCw5\nme8ZBAAAqMhMBb4BAwZowIAB7q4FAAAAbmAq8N13333urgMAAABuYirwvf/++9cc69+/v8uKAQAA\ngOuZCnz/fcNGRkaGfv75Z0VERBD4AAAAKjhTgW/FihW/W/b+++/r8OHDLi8IAAAArmXqsSxXc//9\n9+uDDz5wZS0AAABwA1Nn+BwOR7HXOTk5Wr9+vWrVquWWogAAAOA6pgLfbbfd9rtv2QgKCtKMGTPc\nUhSsyVFYILu3j6fLqNA4RgAAdzAV+D755JNir6tXr67AwEC3FATrsnv7aHfiCE+XUaFFTljq6RIA\nABZkKvA1atTI3XUAAADATaYU5zoAABEvSURBVEoMfEOHDv3dpdz/ZLPZ9NZbb7m8KAAAALhOiYGv\nT58+V12elpamFStWKDc31y1FAQAAwHVKDHwPPvhgsdfZ2dlasmSJ3nvvPfXq1UtPPfWUW4sDAABA\n2Zn6DN/Fixe1dOlSJScnq3PnzlqzZo3++Mc/urs2AAAAuECJgS83N1dvvfWWli1bpnbt2undd9/V\nrbfeWl61AQAAwAVKDHzR0dFyOBwaMWKEwsPDlZGRoYyMjGLrtG/f3q0FAgAAoGxKDHzVqlWTJK1c\nufKq4zab7XfP6AMAAEDFUmLg2759e3nVAQAAADexe7oAAAAAuBeBDwAAwOIIfADgAY7CAk+XUOFx\njADXMfUcPgCAa9m9fbQ7cYSny6jQIics9XQJgGVwhg8AAMDiCHwAAAAWR+ADAACwuHIJfAkJCYqO\njlaLFi108OBB5/KjR4/qoYceUvfu3fXQQw/p2LFjpsYAAABgXrkEvi5duig5OVmNGjUqtjwuLk6D\nBw/W1q1bNXjwYMXGxpoaAwAAgHnlEviioqIUEhJSbFlmZqYOHDig3r17S5J69+6tAwcOKCsrq8Qx\nAAAAlI7HHsuSmpqqoKAgeXl5SZK8vLzUoEEDpaamyjCMa44FBgaWap6UlBSX144bExkZ6ekSKoXd\nu3dfd50bPZb0Q8VBP5hzvX5wZy/wOzLHzL9Z18OxNqcs/WD55/CFh4fLz8/P02UAprnzHz76AZWN\nu/qBXnAdwlr5Kcux9ljgCwkJUVpamoqKiuTl5aWioiKlp6crJCREhmFccwwAAACl47HHstSrV09h\nYWHauHGjJGnjxo0KCwtTYGBgiWMAAAAonXI5wzdz5kxt27ZNGRkZGjZsmAICArRp0yZNmzZNkyZN\n0qJFi1S7dm0lJCQ4tylpDAAAAOaVS+B74YUX9MILL/xueWhoqFavXn3VbUoaAwAAgHlV/ps28guK\nPF1ChccxAgCgcrP8XbrX4+vjpcETkj1dRoX2buLDni4BAACUQZU/wwcAAGB1BD4AAACLI/ABAABY\nHIEPAADA4gh8AAAAFkfgAwAAsDgCHwAAgMUR+AAAACyOwAcAAGBxBD4AAACLI/ABAABYHIEPAADA\n4gh8AAAAFkfgAwAAsDgCHwAAgMUR+AAAACyOwAfAKb+gyNMlVHgcIwCVkbenCwBQcfj6eGnwhGRP\nl1GhvZv4sKdLAIBS4wwfAACAxRH4AAAALI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAW\nR+ADAACwOAIfAACAxRH4AAAALI7ABwAAYHEEPgAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAWR+ADAACw\nOAIfAACAxRH4AAAALI7ABwAAYHHeni5AkqKjo+Xr6ys/Pz9JUkxMjDp06KC9e/cqNjZWeXl5atSo\nkebNm6d69ep5uFoAAIDKpUIEPklauHChmjdv7nztcDg0fvx4zZkzR1FRUVq0aJHmz5+vOXPmeLBK\nAACAyqfCXtJNSUmRn5+foqKiJEkDBw7Uli1bPFwVAABA5VNhzvDFxMTIMAxFRkZq3LhxSk1NVcOG\nDZ3jgYGBcjgcOnv2rAICAjxYKQAAQOVSIQJfcnKyQkJClJ+fr1mzZik+Pl7dunVzyb5TUlJKHI+M\njHTJPFa3e/fuMu+DY22OmWN9o8eSfnAN+qH8XO9Yu6sXyrLvqoZ+KD9l6YcKEfhCQkIkSb6+vho8\neLBGjhypRx55RKdPn3auk5WVJbvdXuqze+Hh4c6bQXDjaMby485jTT+4Bv1Qftx1rOkF16Efyk9Z\njrXHP8N3+fJlXbhwQZJkGIY+/PBDhYWFKTw8XLm5udq1a5ckadWqVerRo4cnSwUAAKiUPH6GLzMz\nU88884yKiorkcDgUGhqquLg42e12JSYmKi4urthjWQAAAFA6Hg98TZo00dq1a6861qZNG23YsKGc\nKwIAALAWj1/SBQAAgHsR+AAAACyOwAcAAGBxBD4AAACLI/ABAABYHIEPAADA4gh8AAAAFkfgAwAA\nsDgCHwAAgMUR+AAAACyOwAcAAGBxBD4AAACLI/ABAABYHIEPAADA4gh8AAAAFkfgAwAAsDgCHwAA\ngMUR+AAAACyOwAcAAGBxBD4AAACLI/ABAABYHIEPAADA4gh8AAAAFkfgAwAAsDgCHwAAgMUR+AAA\nACyOwAcAAGBxBD4AAACLI/ABAABYHIEPAADA4gh8AAAAFkfgAwAAsDgCHwAAgMUR+AAAACyOwAcA\nAGBxBD4AAACLI/ABAABYHIEPAADA4gh8AAAAFkfgAwAAsLgKH/iOHj2qhx56SN27d9dDDz2kY8eO\nebokAACASqXCB764uDgNHjxYW7du1eDBgxUbG+vpkgAAACoVb08XUJLMzEwdOHBAy5cvlyT17t1b\nM2bMUFZWlgIDA0vc1jAMSVJ+fv5156nt71P2Yi0sLy/PdTurVst1+7Kg0hxrX19f2Ww2U+vSD65D\nP5Qfs8faXb0g0Q/XQz+Un7L2g8349b/+CiglJUUTJ07Upk2bnMt69eqlefPm6fbbby9x2wsXLujg\nwYPuLhHwmPDwcPn5+Zlal36AldELwG+u1Q8V+gxfWdSoUUPNmzeXj4+P6b/8gMrE19fX9Lr0A6yM\nXgB+c61+qNCBLyQkRGlpaSoqKpKXl5eKioqUnp6ukJCQ625rt9tVqxanhwGJfgB+RS+gqqrQN23U\nq1dPYWFh2rhxoyRp48aNCgsLu+7n9wAAAPCbCv0ZPkk6fPiwJk2apPPnz6t27dpKSEhQs2bNPF0W\nAABApVHhAx8AAADKpkJf0gUAAEDZEfgAAAAsjsAHAABgcQQ+AAAAiyPwudDHH3+snj17ql+/fjpy\n5Ihb55o0aZLeeecdt85RFb3yyitKSEjwdBmVHr1gDfSDa9AP1lDZ+6FCP3i5slm1apVGjx6tnj17\neroUwKPoBeA39AMqAgKfi8yePVu7d+/W0aNH9e677yomJkbz58/XpUuXJEmjR49W586ddfLkST3w\nwAMaMGCAvvjiC+Xm5mr+/PlatWqV/vWvf6latWpatGiR6tevrx9//FHTp09XTk6O8vLyNGDAAP3v\n//7v7+bOz8/Xyy+/rH/+85/Kz89XixYtNG3aNNWoUaOcj4JntWjRQmPHjtXHH3+ss2fPaubMmfr6\n66/1xRdfqLCwUAsWLFBoaKjOnDmjcePG6dKlS8rLy1OnTp00YcKEq+5zyZIl2rZtm4qKihQUFKQZ\nM2aofv365fzOKhd6oWKgHyoG+qFioB8kGXCZIUOGGNu3bzfOnTtn9O3b10hLSzMMwzDS0tKMDh06\nGOfOnTN+/vlno3nz5sann35qGIZhvPHGG0ZkZKRx4MABwzAMIy4uznjppZcMwzCMCxcuGHl5eYZh\nGMbFixeNnj17Gj/99JNhGIYxceJEY8WKFYZhGEZSUpKRlJTkrCMxMdG5j6qkefPmxjvvvGMYhmF8\n+OGHRuvWrY3t27cbhmEYS5YsMZ577jnDMAwjNzfXuHjxomEYhpGfn28MHTrU+Mc//mEYhmEsXLjQ\nmDt3rmEYhrF27VrjhRdeMIqKigzDMIzk5GRj3Lhx5fqeKit6wfPoh4qDfvA8+sEwOMPnBnv27NHJ\nkyf12GOPOZfZbDYdP35cdevWlb+/vzp37ixJuv322xUcHKywsDDn66+//lqSlJubq2nTpunHH3+U\nzWZTenq6fvjhB4WGhhabb/v27bp48aK2bt0q6cpfdS1btiyHd1rx/HrJ5Pbbb5ck3XPPPZKk8PBw\nffTRR5KkoqIiJSYmas+ePTIMQxkZGfrhhx/UsWPHYvvavn27UlJSdN999zm3q1mzZnm9FUugFzyL\nfqhY6AfPqur9QOBzA8Mw1KJFCyUnJ/9u7OTJk/L19XW+ttvtxV57eXmpqKhIkvTSSy+pfv36mjt3\nrry9vTV8+HDl5eVddb64uDi1b9/eDe+mcvHz85P0++Nqt9tVWFgoSVq+fLnOnz+v1atXy8/PT1On\nTr3mcR05cqT69+9fPsVbEL3gWfRDxUI/eFZV7wfu0nWDiIgIHT9+XDt27HAu27dvn4xSfovdhQsX\nFBwcLG9vbx08eFC7du266nrR0dF68803lZubK0m6ePGiDh8+fONvwOIuXLig+vXry8/PT2lpafrk\nk0+uul50dLTeffddnTt3TtKVv45/+OGH8iy10qMXKj76ofzQDxWflfuBM3xuUKdOHS1atEjz5s3T\n7NmzVVBQoCZNmmjx4sWl2s/IkSM1YcIEvf/++7r55pvVtm3bq673+OOP69VXX1X//v1ls9lks9n0\n9NNP/+70Pq4YOnSoxowZo969eysoKOiaf/3269dPZ8+e1ZAhQyRd+Ytu0KBBVfqSSGnRCxUf/VB+\n6IeKz8r9YDNK+6cFAAAAKhUu6QIAAFgcgQ8AAMDiCHwAAAAWR+ADAACwOAIfAACAxRH44HZ///vf\nNWjQIE+XAXgcvQD8hn4oXzyHrwrbtGmT3nzzTR06dEjVq1dX48aN1a9fPw0ePFg2m83T5QHlhl4A\nfkM/WBNn+KqoZcuWadasWXr00Uf15Zdf6uuvv9b06dP13XffqaCgwNPlOf36VUKAu9ALwG/oB+si\n8FVBFy5c0MKFCxUXF6cePXqoZs2astlsuu222/Tiiy/K19dX+fn5SkhIUOfOnfWnP/1JsbGxzq/n\n2blzpzp27Khly5apffv2uvvuu/XBBx8495+dna0nn3xSbdq0Uf/+/XXixIli8x8+fFjDhg3TnXfe\nqe7du+vDDz90jk2aNElxcXF67LHH1Lp1a+3cubN8DgqqJHoB+A39YG0Evipoz549ys/PV5cuXa65\nzvz583X06FGtXbtW27ZtU3p6upKSkpzjGRkZunDhgj7//HPNmjVL8fHxzu8UjI+Pl5+fn7788kvN\nnj27WMNfvnxZw4cPV+/evfX111/r5Zdf1vTp0/XTTz8519m4caOefPJJfffdd4qMjHTDEQCuoBeA\n39AP1kbgq4Kys7NVt25deXv/9hHOgQMHKioqSq1atdK3336r9957T5MnT1ZAQIBq1qypJ554Qps2\nbXKu7+3traeeeko+Pj7q1KmT/P39dfToURUVFWnbtm0aPXq0/P391bx5c913333O7T777DM1atRI\nDzzwgLy9vXXbbbepe/fu2rJli3OdLl26KDIyUna7XX5+fuVzUFAl0QvAb+gHa+OmjSooICBA2dnZ\nKiwsdDb2qlWrJEkdO3ZURkaGcnJydP/99zu3MQxDDoej2D7+8x+F6tWr6/Lly8rKylJhYaFCQkKc\nYw0bNnT+fOrUKe3bt09RUVHOZUVFRerTp4/z9X9uC7gTvQD8hn6wNgJfFRQRESFfX1998skn6t69\n++/G69atq2rVqmnTpk0KCgoq1b4DAwPl7e2t1NRUhYaGSpJSU1Od4yEhIWrbtq2WL19etjcBuAC9\nAPyGfrA2LulWQbVr19ZTTz2l6dOna8uWLbp48aIcDoe+//575eTkyG6368EHH9Ts2bOVmZkpSUpL\nS9MXX3xx3X17eXmpW7duevXVV5WTk6OffvpJa9ascY537txZx44d09q1a1VQUKCCggLt27dPhw8f\ndtv7Ba6FXgB+Qz9YG2f4qqjHHntMQUFBWrp0qSZOnKjq1aurSZMmiomJUUREhFq3bq2kpCQNGDBA\n2dnZCgoK0qBBg9ShQ4fr7js2NlbPP/+87rrrLjVr1kz333+/846qmjVr6q9//avmzp2ruXPnyjAM\ntWjRQs8//7y73zJwVfQC8Bv6wbpshmEYni4CAAAA7sMlXQAAAIsj8AEAAFgcgQ8AAMDiCHwAAAAW\nR+ADAACwOAIfAACAxRH4AAAALI7ABwAAYHEEPgAAAIv7fxzK4C7z70wSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LC9aqS5LJ2M",
        "colab_type": "code",
        "outputId": "9f9ed4b9-2574-41ae-ea96-0667b93dc618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# Using Histograms to compare age and sex and their contribution to survival of a person\n",
        "# Plot using seaborn\n",
        "sns.set(style = 'whitegrid', context = 'notebook')\n",
        "# First we create variables labeling the survived column values 0 and 1\n",
        "survived = 'survived'\n",
        "not_survived = 'not survived'\n",
        "\n",
        "\n",
        "# creating a chart where our plots will appear\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
        "\n",
        "# creating women and male variables from the male and female variables in the dataset\n",
        "women = data[data['Sex']=='female']\n",
        "men = data[data['Sex']=='male']\n",
        "\n",
        "# Plotting the histogram of the women and specifying the bin sizes, and labels as we created earlier\n",
        "\n",
        "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n",
        "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n",
        "ax.legend()\n",
        "ax.set_title('Female')\n",
        "\n",
        "# Plotting the histogram of the men and specifying the bin sizes, and labels as we created earlier\n",
        "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n",
        "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n",
        "ax.legend()\n",
        "_ = ax.set_title('Male')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEcCAYAAADjpzHMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzcLfIBVWK5v",
        "colab_type": "text"
      },
      "source": [
        "# <font color = \"Yellow\"> **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgpCB-alY60R",
        "colab_type": "text"
      },
      "source": [
        "As was stated earlier women, children and the upper class were given priority to get to safety, we therefore have to establish the title of the passengers, the size of a family or whether the passenger was onboard alone.\n",
        "\n",
        "It is difficult to establish any information on a passenger based on their names, some are nicknames. So we try establish the title of each passenger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6U6kKxWY6ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's establish the title of each passenger\n",
        "\n",
        "for x in data:\n",
        "    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYvW1kH4ZJb9",
        "colab_type": "code",
        "outputId": "46b31539-7b82-498f-ad3c-e7b2880ee13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#What are the titles extracted from the names ?\n",
        "\n",
        "data.Title.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
              "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n",
              "       'Jonkheer'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 546
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D07jdJQ6ZOAK",
        "colab_type": "text"
      },
      "source": [
        "The titles are many in number and usually we just need to establish if it's a Miss, Mrs, Mr or Master and every other title can be referred to as 'other'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQuJkMQ3ZK3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in data:\n",
        "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n",
        "\n",
        "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Mme', 'Mrs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-VqgBiOZejR",
        "colab_type": "code",
        "outputId": "6e2e60f0-593f-4c64-dbc6-91af1cdba86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#What are the titles extracted from the names?\n",
        "\n",
        "data.Title.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mr', 'Mrs', 'Miss', 'Master', 'Other'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 550
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rqMXleUZpZe",
        "colab_type": "text"
      },
      "source": [
        "Now we can safely drop the Name column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8F-BOIdZiyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping the name column\n",
        "data.drop('Name', axis=1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgyNVuORZ78w",
        "colab_type": "code",
        "outputId": "e7e5d42b-ff79-4a55-ada4-3c15d6b4a5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# confirming changes\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title\n",
              "0        0      3    male  22.0      1      0   7.2500        S    Mr\n",
              "1        1      1  female  38.0      1      0  71.2833        C   Mrs"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 554
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LavkjORoaR_S",
        "colab_type": "text"
      },
      "source": [
        "We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qINyEgUmaIAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in data:\n",
        "    data['FamSize'] = data['SibSp'] + data['Parch'] + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLrBB3lTaYv-",
        "colab_type": "code",
        "outputId": "174c94e7-1489-4276-8c0a-40d25d06fda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# confirming changes\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>FamSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  FamSize\n",
              "0        0      3    male  22.0      1      0   7.2500        S    Mr        2\n",
              "1        1      1  female  38.0      1      0  71.2833        C   Mrs        2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-gzzFlvak95",
        "colab_type": "text"
      },
      "source": [
        "Was the passenger traveling alone or with a family? If the family size is 1 then they are probably alone, if there are more then the passenger is essentially not alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6XzK5xtakLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in data:\n",
        "    data['Alone?'] = 0\n",
        "    data.loc[data['FamSize'] == 1, 'Alone?'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJK1g_CWasMM",
        "colab_type": "code",
        "outputId": "e7717731-f2c5-42a6-dca2-9e50df14669e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['Alone?'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 559
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bNYwYOCsify",
        "colab_type": "text"
      },
      "source": [
        "Essentially;\n",
        "\n",
        "if Alone = 0, they are not alone\n",
        "\n",
        "if Alone = 1, they are alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwzG5o4gvCcs",
        "colab_type": "code",
        "outputId": "1f9e0608-b8ff-452c-a458-59b67c91d151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "data.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>FamSize</th>\n",
              "      <th>Alone?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.25</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass   Sex   Age  SibSp  ...  Fare  Embarked Title FamSize  Alone?\n",
              "0        0      3  male  22.0      1  ...  7.25         S    Mr       2       0\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 560
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuTueVdCsres",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Thereafter we can drop the colums 'SibSp','Parch' and 'FamSize'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLWjvCg5ssZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['Parch', 'SibSp', 'FamSize'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbj7mCwcstq3",
        "colab_type": "code",
        "outputId": "a7abe7b5-5ba2-4bb1-f183-325470a2d343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "data.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>Alone?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.25</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass   Sex   Age  Fare Embarked Title  Alone?\n",
              "0        0      3  male  22.0  7.25        S    Mr       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQdpjqyktAAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categoricals = ['Sex','Embarked','Title']\n",
        "\n",
        "data = pd.get_dummies(data, columns=['Sex','Embarked','Title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXIWXMwhtIoA",
        "colab_type": "code",
        "outputId": "f0139d5f-879e-4359-ed97-15b9d517365b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Alone?</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Title_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Survived Pclass   Age     Fare  ...  Title_Miss  Title_Mr  Title_Mrs  Title_Other\n",
              "0        0      3  22.0   7.2500  ...           0         1          0            0\n",
              "1        1      1  38.0  71.2833  ...           0         0          1            0\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 564
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP9yQc2SbiFy",
        "colab_type": "text"
      },
      "source": [
        "We must consider the age column, if a passenger was a child they had a higher chance of survival, therefore we must categorize a passenger as adult(1) or child(0) in a new Adult column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9YmvFJDvTg2",
        "colab_type": "code",
        "outputId": "0a41fd33-55a5-44ea-d605-39685aeb3399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "data[\"Adult\"] = 0\n",
        "\n",
        "data[\"Adult\"][data[\"Age\"] >= 18] = 1\n",
        "\n",
        "#Thereafter drop the age column\n",
        "\n",
        "data = data.drop(['Age'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8P005JWvZgI",
        "colab_type": "code",
        "outputId": "38d8f08a-46c1-422a-d380-6a91d14c3a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "data = data[['Pclass','Adult','Fare','Alone?','Sex_female','Sex_male','Embarked_C','Embarked_Q','Embarked_S','Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Other','Survived']]\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Adult</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Alone?</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Title_Other</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Pclass  Adult     Fare  Alone?  ...  Title_Mr  Title_Mrs  Title_Other  Survived\n",
              "0      3      1   7.2500       0  ...         1          0            0         0\n",
              "1      1      1  71.2833       0  ...         0          1            0         1\n",
              "2      3      1   7.9250       1  ...         0          0            0         1\n",
              "3      1      1  53.1000       0  ...         0          1            0         1\n",
              "4      3      1   8.0500       1  ...         1          0            0         0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 566
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUclcZtf1qJz",
        "colab_type": "text"
      },
      "source": [
        "# <font color = yellow> **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNE-_dNJcHSv",
        "colab_type": "text"
      },
      "source": [
        "## <font color = \"red\"> K-Nearest Neighbors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyKKNHTYb6d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into train and test sets\n",
        "# define our X and y\n",
        "\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WygaX7bpcfJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train,y_test = train_test_split (X,y,test_size = 0.2,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGfDpSdvclcF",
        "colab_type": "code",
        "outputId": "7e591943-9863-4525-8bc8-d2559c008abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"Shape of the X_train: \", X_train.shape)\n",
        "print(\"Shape of the y_train: \", y_train.shape)\n",
        "print(\"Shape of the X_test: \", X_test.shape)\n",
        "print(\"Shape of the y_test: \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the X_train:  (712, 14)\n",
            "Shape of the y_train:  (712,)\n",
            "Shape of the X_test:  (179, 14)\n",
            "Shape of the y_test:  (179,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF17S8xfc974",
        "colab_type": "code",
        "outputId": "66a3382f-d7ea-467d-a0c0-24e6b42bd70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "#Perform the K-Nearest Neighbors Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score\n",
        "\n",
        "print('The accuracy :',accuracy_score(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82       105\n",
            "           1       0.75      0.73      0.74        74\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.78      0.78      0.78       179\n",
            "weighted avg       0.79      0.79      0.79       179\n",
            "\n",
            "[[87 18]\n",
            " [20 54]]\n",
            "The accuracy : 0.7877094972067039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtK9-FkTdhxK",
        "colab_type": "text"
      },
      "source": [
        "Let us repeat the step using 70% training data and 30% test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnY4k6nudMAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train,y_test = train_test_split (X,y,test_size = 0.3,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJKkf0D-dn-3",
        "colab_type": "code",
        "outputId": "6728a463-ac2f-47b0-f5c6-ef44bc788715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"Shape of the X_train: \", X_train.shape)\n",
        "print(\"Shape of the y_train: \", y_train.shape)\n",
        "print(\"Shape of the X_test: \", X_test.shape)\n",
        "print(\"Shape of the y_test: \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the X_train:  (623, 14)\n",
            "Shape of the y_train:  (623,)\n",
            "Shape of the X_test:  (268, 14)\n",
            "Shape of the y_test:  (268,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep2A9cH_dqYl",
        "colab_type": "code",
        "outputId": "ee84d020-cf64-46cd-c2bc-a73cd9858fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "#Perform the K-Nearest Neighbors Classifier\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score\n",
        "\n",
        "print('The accuracy :',accuracy_score(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       157\n",
            "           1       0.77      0.73      0.75       111\n",
            "\n",
            "    accuracy                           0.80       268\n",
            "   macro avg       0.79      0.79      0.79       268\n",
            "weighted avg       0.80      0.80      0.80       268\n",
            "\n",
            "[[133  24]\n",
            " [ 30  81]]\n",
            "The accuracy : 0.7985074626865671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqo7CJOd3Yn",
        "colab_type": "text"
      },
      "source": [
        "Let's use 60% training data and 40% test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82OkOqhOdy3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train and test splits\n",
        "X_train, X_test,y_train,y_test = train_test_split (X,y,test_size = 0.4,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJSR-n0geClp",
        "colab_type": "code",
        "outputId": "bfd4edac-3014-4bff-b9f7-c3631026627d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"Shape of the X_train: \", X_train.shape)\n",
        "print(\"Shape of the y_train: \", y_train.shape)\n",
        "print(\"Shape of the X_test: \", X_test.shape)\n",
        "print(\"Shape of the y_test: \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the X_train:  (534, 14)\n",
            "Shape of the y_train:  (534,)\n",
            "Shape of the X_test:  (357, 14)\n",
            "Shape of the y_test:  (357,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l180JW2deFAn",
        "colab_type": "code",
        "outputId": "9aeef087-3356-404d-8c27-12d4a03812ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "#Perform the K-Nearest Neighbors Classifier\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score\n",
        "\n",
        "print('The accuracy :',accuracy_score(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83       216\n",
            "           1       0.76      0.69      0.72       141\n",
            "\n",
            "    accuracy                           0.79       357\n",
            "   macro avg       0.78      0.77      0.78       357\n",
            "weighted avg       0.79      0.79      0.79       357\n",
            "\n",
            "[[185  31]\n",
            " [ 44  97]]\n",
            "The accuracy : 0.7899159663865546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBtzSMRceaWX",
        "colab_type": "text"
      },
      "source": [
        "### <font color = cyan> Optimize the K-Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfRzT0blenDw",
        "colab_type": "text"
      },
      "source": [
        "Predict the scores using KNearestNeighbors (KNN) with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd6qxR13eGTS",
        "colab_type": "code",
        "outputId": "1d583d19-ae56-4b13-e70f-2dba3130f219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "k_range = list(range(1,10))\n",
        "weights_options = ['uniform','distance']\n",
        "k_grid = dict(n_neighbors=k_range, weights = weights_options)\n",
        "grid = GridSearchCV(model, k_grid, cv=10, scoring = 'precision')\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='precision', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 577
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kRC6LBerpk",
        "colab_type": "code",
        "outputId": "932da8d0-b5a2-46a9-968d-87287826a928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid.cv_results_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.00490344, 0.00392129, 0.00389423, 0.0039592 , 0.00380168,\n",
              "        0.00394795, 0.00405011, 0.00383685, 0.0038553 , 0.00369191,\n",
              "        0.00385966, 0.00413589, 0.00443096, 0.00384734, 0.0039923 ,\n",
              "        0.00382383, 0.00439386, 0.00438299]),\n",
              " 'mean_score_time': array([0.00531802, 0.00339224, 0.00494053, 0.0034229 , 0.00479765,\n",
              "        0.00339794, 0.00535688, 0.00331664, 0.00495872, 0.00318084,\n",
              "        0.00494077, 0.00345004, 0.00550382, 0.00328739, 0.00495901,\n",
              "        0.00324695, 0.00564256, 0.00375152]),\n",
              " 'mean_test_score': array([0.65216554, 0.65216554, 0.77953439, 0.72162013, 0.72393717,\n",
              "        0.71634173, 0.73675824, 0.71251534, 0.71175813, 0.70841767,\n",
              "        0.73478167, 0.716566  , 0.67244579, 0.72286282, 0.69593048,\n",
              "        0.70293054, 0.63389086, 0.67475758]),\n",
              " 'param_n_neighbors': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
              "                    'uniform', 'distance', 'uniform', 'distance',\n",
              "                    'uniform', 'distance', 'uniform', 'distance',\n",
              "                    'uniform', 'distance', 'uniform', 'distance',\n",
              "                    'uniform', 'distance'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'n_neighbors': 1, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 1, 'weights': 'distance'},\n",
              "  {'n_neighbors': 2, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 2, 'weights': 'distance'},\n",
              "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 3, 'weights': 'distance'},\n",
              "  {'n_neighbors': 4, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 4, 'weights': 'distance'},\n",
              "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 5, 'weights': 'distance'},\n",
              "  {'n_neighbors': 6, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 6, 'weights': 'distance'},\n",
              "  {'n_neighbors': 7, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 7, 'weights': 'distance'},\n",
              "  {'n_neighbors': 8, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 8, 'weights': 'distance'},\n",
              "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
              "  {'n_neighbors': 9, 'weights': 'distance'}],\n",
              " 'rank_test_score': array([16, 16,  1,  6,  4,  8,  2,  9, 10, 11,  3,  7, 15,  5, 13, 12, 18,\n",
              "        14], dtype=int32),\n",
              " 'split0_test_score': array([0.6       , 0.6       , 0.65      , 0.65217391, 0.68181818,\n",
              "        0.66666667, 0.75      , 0.65217391, 0.65217391, 0.65217391,\n",
              "        0.68421053, 0.65217391, 0.66666667, 0.68181818, 0.7       ,\n",
              "        0.60869565, 0.66666667, 0.63636364]),\n",
              " 'split1_test_score': array([0.56521739, 0.56521739, 0.66666667, 0.63157895, 0.68181818,\n",
              "        0.69565217, 0.625     , 0.66666667, 0.65217391, 0.66666667,\n",
              "        0.66666667, 0.65217391, 0.64      , 0.66666667, 0.68421053,\n",
              "        0.68181818, 0.69565217, 0.69565217]),\n",
              " 'split2_test_score': array([0.57894737, 0.57894737, 0.61538462, 0.64705882, 0.6875    ,\n",
              "        0.64705882, 0.8       , 0.64705882, 0.73684211, 0.70588235,\n",
              "        0.78571429, 0.6875    , 0.75      , 0.71428571, 0.76923077,\n",
              "        0.70588235, 0.66666667, 0.66666667]),\n",
              " 'split3_test_score': array([0.66666667, 0.66666667, 0.64705882, 0.68181818, 0.66666667,\n",
              "        0.69565217, 0.57142857, 0.72727273, 0.7       , 0.7       ,\n",
              "        0.68421053, 0.71428571, 0.66666667, 0.71428571, 0.66666667,\n",
              "        0.71428571, 0.61904762, 0.68181818]),\n",
              " 'split4_test_score': array([0.64705882, 0.64705882, 0.85714286, 0.64285714, 0.66666667,\n",
              "        0.64285714, 0.66666667, 0.61538462, 0.5625    , 0.5625    ,\n",
              "        0.58333333, 0.5625    , 0.5       , 0.58823529, 0.53846154,\n",
              "        0.52631579, 0.5       , 0.55555556]),\n",
              " 'split5_test_score': array([0.75      , 0.75      , 1.        , 0.78571429, 0.70588235,\n",
              "        0.75      , 0.83333333, 0.75      , 0.66666667, 0.6875    ,\n",
              "        0.76923077, 0.78571429, 0.66666667, 0.73333333, 0.75      ,\n",
              "        0.76923077, 0.5625    , 0.66666667]),\n",
              " 'split6_test_score': array([0.65      , 0.65      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.6875    , 0.73333333, 0.70588235, 0.76470588, 0.70588235,\n",
              "        0.69230769, 0.70588235, 0.63157895, 0.6875    , 0.53333333,\n",
              "        0.61111111, 0.5625    , 0.5625    ]),\n",
              " 'split7_test_score': array([0.57692308, 0.57692308, 0.7       , 0.625     , 0.65      ,\n",
              "        0.63636364, 0.625     , 0.61904762, 0.57894737, 0.6       ,\n",
              "        0.625     , 0.6       , 0.57894737, 0.63157895, 0.58823529,\n",
              "        0.6       , 0.57894737, 0.6       ]),\n",
              " 'split8_test_score': array([0.73684211, 0.73684211, 1.        , 0.86666667, 0.86666667,\n",
              "        0.86666667, 0.91666667, 0.86666667, 0.92857143, 0.92857143,\n",
              "        1.        , 0.92307692, 0.84615385, 0.92857143, 0.91666667,\n",
              "        0.92307692, 0.76470588, 0.8       ]),\n",
              " 'split9_test_score': array([0.75      , 0.75      , 0.90909091, 0.93333333, 0.88235294,\n",
              "        0.875     , 0.84615385, 0.875     , 0.875     , 0.875     ,\n",
              "        0.85714286, 0.88235294, 0.77777778, 0.88235294, 0.8125    ,\n",
              "        0.88888889, 0.72222222, 0.88235294]),\n",
              " 'std_fit_time': array([0.00167651, 0.00021232, 0.00028145, 0.000266  , 0.00017505,\n",
              "        0.0002214 , 0.00023814, 0.00016735, 0.00030805, 0.00011662,\n",
              "        0.00017592, 0.00099497, 0.00076397, 0.00026195, 0.00032232,\n",
              "        0.00017879, 0.0010016 , 0.00034232]),\n",
              " 'std_score_time': array([0.00084847, 0.00019323, 0.00022055, 0.00043087, 0.00030219,\n",
              "        0.00021899, 0.00130133, 0.00035118, 0.00044903, 0.00023646,\n",
              "        0.00024404, 0.00045415, 0.0009405 , 0.0001495 , 0.0003316 ,\n",
              "        0.00011501, 0.00121987, 0.00026247]),\n",
              " 'std_test_score': array([0.0691794 , 0.0691794 , 0.14185533, 0.10314421, 0.07960824,\n",
              "        0.08345962, 0.1072727 , 0.08945899, 0.11237318, 0.10709411,\n",
              "        0.11646505, 0.11022449, 0.0941204 , 0.10027981, 0.11595353,\n",
              "        0.12129408, 0.07889052, 0.09657771])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 578
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00bAJXIgev5l",
        "colab_type": "code",
        "outputId": "2a9b2552-436b-41ce-d875-4cf46e844b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"Best Score: \",str(grid.best_score_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.779534387181446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4_X0FPEey59",
        "colab_type": "code",
        "outputId": "fc841372-7d5f-42ab-9bda-bef7523daa53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"Best Parameters: \",str(grid.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'n_neighbors': 2, 'weights': 'uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn6pfd6me3L8",
        "colab_type": "code",
        "outputId": "1f289674-0c8d-4f7c-efbb-d6bfe5569e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print (\"Best Estimators: \",str(grid.best_estimator_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Estimators:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
            "                     weights='uniform')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-6ds1b3e5M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict scores\n",
        "\n",
        "y_pred = grid.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOdrqNVXe8hc",
        "colab_type": "code",
        "outputId": "3ae2f781-0013-4c4b-ab48-ea13e83fb37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Calculate Accuracy\n",
        "\n",
        "print('The accuracy :',accuracy_score(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy : 0.7535014005602241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCN4kRhe_Cm",
        "colab_type": "code",
        "outputId": "c39f5bd7-f454-4f81-9879-59dd705197d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Calculate precision, recall, and fbeta_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.92      0.82       216\n",
            "           1       0.80      0.50      0.61       141\n",
            "\n",
            "    accuracy                           0.75       357\n",
            "   macro avg       0.77      0.71      0.72       357\n",
            "weighted avg       0.76      0.75      0.74       357\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqFnWhR3fFUy",
        "colab_type": "text"
      },
      "source": [
        "A larger dataset would result in a higher level of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xtL5jQwgrvT",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Challenging the solution "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BOFq4liUXu",
        "colab_type": "text"
      },
      "source": [
        "### <font color = cyan> Cleaning the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maHca145ifH-",
        "colab_type": "code",
        "outputId": "f01fad79-16a8-493c-d57d-994931d6baf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# checking data types\n",
        "test.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Sex             object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Ticket          object\n",
              "Fare           float64\n",
              "Cabin           object\n",
              "Embarked        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-8VKRvMi5he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the relevant data types to categorical\n",
        "\n",
        "# Creating a list of the numerical columns in the dataset.\n",
        "numeric = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "\n",
        "categoricals = ['Pclass','Sex','Embarked']\n",
        "\n",
        "objects = ['Name']\n",
        "\n",
        "for x in test.columns:\n",
        "   if x in numeric:\n",
        "       test[x]=pd.to_numeric(test[x])\n",
        "   elif x in categoricals:\n",
        "        test[x]=test[x].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXBEp9EXi5cS",
        "colab_type": "code",
        "outputId": "ae17b3b1-2673-490e-e7d6-2da547cd46b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "test.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId       int64\n",
              "Pclass         category\n",
              "Name             object\n",
              "Sex            category\n",
              "Age             float64\n",
              "SibSp             int64\n",
              "Parch             int64\n",
              "Ticket           object\n",
              "Fare            float64\n",
              "Cabin            object\n",
              "Embarked       category\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 601
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQ8fVIij1d-",
        "colab_type": "code",
        "outputId": "570510b4-7756-4cab-9f4c-8f22eff3b2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age             86\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             1\n",
              "Cabin          327\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 602
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK5lU7fqi5as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replacing all missing values with the mean in the age column\n",
        "test['Age'].fillna((test['Age'].mean()), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L83AFtYwwoF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# column cabin containing categorical values \n",
        "# dropping the columns since it contains very many missing values\n",
        "test.drop('Cabin', axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz1rmFUJwaL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace the null values in the Embarked column with the mode\n",
        "\n",
        "test['Fare'].fillna(test['Fare'].mode()[0], inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE2bamMkwxso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping the unnecessary columns\n",
        "test.drop(['PassengerId', 'Ticket'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qvkohYP0kYA",
        "colab_type": "code",
        "outputId": "064b845d-106d-4676-8495-8f436e280916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass      0\n",
              "Name        0\n",
              "Sex         0\n",
              "Age         0\n",
              "SibSp       0\n",
              "Parch       0\n",
              "Fare        0\n",
              "Embarked    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 607
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnhVnlzmywH5",
        "colab_type": "text"
      },
      "source": [
        "### <font color = cyan> Feature Engineering for Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2hPdaIRyvP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's establish the title of each passenger\n",
        "\n",
        "for x in test:\n",
        "    test['Title'] = test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auy_VcjQzEzj",
        "colab_type": "code",
        "outputId": "c3a30104-8570-4a79-9ebc-78971ca109f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#What are the titles extracted from the names ?\n",
        "test.Title.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Col', 'Rev', 'Dr', 'Dona'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 609
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xZXPPDEzJ1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in test:\n",
        "    test['Title'] = test['Title'].replace(['Col', 'Dr', 'Rev', 'Sir', 'Dona'], 'Other')\n",
        "\n",
        "    test['Title'] = test['Title'].replace('Mlle', 'Miss')\n",
        "    test['Title'] = test['Title'].replace('Ms', 'Miss')\n",
        "    test['Title'] = test['Title'].replace('Mme', 'Mrs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFnA5oXVzNHy",
        "colab_type": "code",
        "outputId": "bc252a8d-00a7-4e4e-b854-28ce89260978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#What are the titles extracted from the names?\n",
        "\n",
        "test.Title.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mr', 'Mrs', 'Miss', 'Master', 'Other'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 611
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_C4K3RgzRuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping the name column\n",
        "test.drop('Name', axis=1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93R0VyLlzSmC",
        "colab_type": "code",
        "outputId": "d7b30da5-42d9-4f2d-ad2c-aec8f73ae13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>Q</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Pclass     Sex   Age  SibSp  Parch    Fare Embarked Title\n",
              "0      3    male  34.5      0      0  7.8292        Q    Mr\n",
              "1      3  female  47.0      1      0  7.0000        S   Mrs"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwXejXkqzZVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in test:\n",
        "    test['FamSize'] = test['SibSp'] + test['Parch'] + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFQ2whqczih0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in test:\n",
        "    test['Alone?'] = 0\n",
        "    test.loc[test['FamSize'] == 1, 'Alone?'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmR9pDCSzifO",
        "colab_type": "code",
        "outputId": "6c9ddcfc-9937-4f8f-cb2f-a973f5e3ab14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test['Alone?'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 616
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3yqFyjezZS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.drop(['Parch', 'SibSp', 'FamSize'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTL9RoJqx5St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categoricals = ['Sex','Embarked','Title']\n",
        "\n",
        "test = pd.get_dummies(test, columns=['Sex','Embarked','Title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csnl8VKEyZ0W",
        "colab_type": "code",
        "outputId": "5577a3c5-10e6-45d2-d3f4-a5ac28a5e3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "test.head(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Alone?</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Title_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>34.5</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>47.0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>62.0</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Pclass   Age    Fare  Alone?  ...  Title_Miss  Title_Mr  Title_Mrs  Title_Other\n",
              "0      3  34.5  7.8292       1  ...           0         1          0            0\n",
              "1      3  47.0  7.0000       0  ...           0         0          1            0\n",
              "2      2  62.0  9.6875       1  ...           0         1          0            0\n",
              "3      3  27.0  8.6625       1  ...           0         1          0            0\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 620
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1VTzapYyTKn",
        "colab_type": "code",
        "outputId": "143d48b8-4186-4dd8-c070-d724a72368b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test[\"Adult\"] = 0\n",
        "\n",
        "test[\"Adult\"][test[\"Age\"] >= 18] = 1\n",
        "\n",
        "#Thereafter drop the age column\n",
        "\n",
        "test = test.drop(['Age'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr5lfitl02w3",
        "colab_type": "code",
        "outputId": "8d94d484-d276-4d3c-fb73-271d943b847b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pclass', 'Fare', 'Alone?', 'Sex_female', 'Sex_male', 'Embarked_C',\n",
              "       'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Miss', 'Title_Mr',\n",
              "       'Title_Mrs', 'Title_Other', 'Adult'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 624
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBIVoek50Lv7",
        "colab_type": "code",
        "outputId": "fa277625-2474-40e0-de3e-d41d52f00d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "test = test[['Pclass','Adult','Fare','Alone?','Sex_female','Sex_male','Embarked_C','Embarked_Q','Embarked_S','Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Other']]\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Adult</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Alone?</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Title_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Pclass  Adult     Fare  Alone?  ...  Title_Miss  Title_Mr  Title_Mrs  Title_Other\n",
              "0      3      1   7.8292       1  ...           0         1          0            0\n",
              "1      3      1   7.0000       0  ...           0         0          1            0\n",
              "2      2      1   9.6875       1  ...           0         1          0            0\n",
              "3      3      1   8.6625       1  ...           0         1          0            0\n",
              "4      3      1  12.2875       0  ...           0         0          1            0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 625
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioyX7sg-g60C",
        "colab_type": "text"
      },
      "source": [
        "### <font color = cyan> Random Forest Classifier\n",
        "\n",
        "* Using Random Forest which is an Ensemble algorithm.\n",
        "* Also considering the Train data without splitting it further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW8x0ZpAw9z0",
        "colab_type": "code",
        "outputId": "75cbb700-531a-487a-f2ad-48b63508d9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# Splitting the data into test and train sets as provided earlier\n",
        "# NOTE: No further split is done.\n",
        "\n",
        "X_train = data.iloc[:, :-1]\n",
        "y_train = data.iloc[:,-1]\n",
        "X_test = test.copy()\n",
        "\n",
        "# Instantiating our model\n",
        "# Training the model\n",
        "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
        "                                       min_samples_leaf = 1, \n",
        "                                       min_samples_split = 10,   \n",
        "                                       n_estimators=100, \n",
        "                                       max_features='auto', \n",
        "                                       oob_score=True, \n",
        "                                       random_state=10,\n",
        "                                       n_jobs=-1) #  Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "random_forest.score(X_train, y_train)\n",
        "\n",
        "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
        "print(round(acc_random_forest,2,), \"%\")\n",
        "\n",
        "# Generating cross-validated estimates for each input data point\n",
        "predictions = cross_val_predict(random_forest, X_train, y_train, cv=3)\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_train, predictions))\n",
        "print(classification_report(y_train, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88.89 %\n",
            "[[479  70]\n",
            " [ 94 248]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       549\n",
            "           1       0.78      0.73      0.75       342\n",
            "\n",
            "    accuracy                           0.82       891\n",
            "   macro avg       0.81      0.80      0.80       891\n",
            "weighted avg       0.81      0.82      0.81       891\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh2K0Eh53OPd",
        "colab_type": "text"
      },
      "source": [
        "* The Random Forest Classifier model yields 89% accuracy.\n",
        "\n",
        "* This is a better model compared to KNN.\n",
        "* However, tunning may be needed to assess the model adequately.\n",
        "\n",
        "* The Recall score increased compared to other models.\n",
        "\n",
        "* Interprating the confusion matrix:\n",
        "* The first row is about the not-survived-predictions:\n",
        "     * 479 passengers were correctly classified as not survived (called true negatives) \n",
        "     * 70 were wrongly classified as not survived (false positives).\n",
        "* The second row is about the survived-predictions: \n",
        "     * 94 passengers where wrongly classified as survived (false negatives) and\n",
        "     * 248 were correctly classified as survived (true positives).\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34wxiA8Y1VO3",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4N1ACok1RdN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* From the analysis: Tuning and Optimizing the KNN model is highly recommended to improve the performance of the model.\n",
        "* Splitting the data into 70,30 train and test sets was the best in the Titanic dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epuo2NJP7ovp",
        "colab_type": "text"
      },
      "source": [
        "# <font color = yellow> **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfz9sECMfliD",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKjeGeCafgKD",
        "colab_type": "code",
        "outputId": "2fe97749-02e1-405c-f9fb-74cab81bb110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "spam = pd.read_csv('spambase.data')\n",
        "spam"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0.64</th>\n",
              "      <th>0.64.1</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.64.2</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.32.1</th>\n",
              "      <th>0.11</th>\n",
              "      <th>1.29</th>\n",
              "      <th>1.93</th>\n",
              "      <th>0.12</th>\n",
              "      <th>0.96</th>\n",
              "      <th>0.13</th>\n",
              "      <th>0.14</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.16</th>\n",
              "      <th>0.17</th>\n",
              "      <th>0.18</th>\n",
              "      <th>0.19</th>\n",
              "      <th>0.20</th>\n",
              "      <th>0.21</th>\n",
              "      <th>0.22</th>\n",
              "      <th>0.23</th>\n",
              "      <th>0.24</th>\n",
              "      <th>0.25</th>\n",
              "      <th>0.26</th>\n",
              "      <th>0.27</th>\n",
              "      <th>0.28</th>\n",
              "      <th>0.29</th>\n",
              "      <th>0.30</th>\n",
              "      <th>0.31</th>\n",
              "      <th>0.32.2</th>\n",
              "      <th>0.33</th>\n",
              "      <th>0.34</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.36</th>\n",
              "      <th>0.37</th>\n",
              "      <th>0.38</th>\n",
              "      <th>0.39</th>\n",
              "      <th>0.40</th>\n",
              "      <th>0.41</th>\n",
              "      <th>0.42</th>\n",
              "      <th>0.778</th>\n",
              "      <th>0.43</th>\n",
              "      <th>0.44</th>\n",
              "      <th>3.756</th>\n",
              "      <th>61</th>\n",
              "      <th>278</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4600 rows × 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  0.64  0.64.1  0.1  0.32   0.2  ...   0.43   0.44  3.756   61   278  1\n",
              "0     0.21  0.28    0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028  1\n",
              "1     0.06  0.00    0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259  1\n",
              "2     0.00  0.00    0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191  1\n",
              "3     0.00  0.00    0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191  1\n",
              "4     0.00  0.00    0.00  0.0  1.85  0.00  ...  0.000  0.000  3.000   15    54  1\n",
              "...    ...   ...     ...  ...   ...   ...  ...    ...    ...    ...  ...   ... ..\n",
              "4595  0.31  0.00    0.62  0.0  0.00  0.31  ...  0.000  0.000  1.142    3    88  0\n",
              "4596  0.00  0.00    0.00  0.0  0.00  0.00  ...  0.000  0.000  1.555    4    14  0\n",
              "4597  0.30  0.00    0.30  0.0  0.00  0.00  ...  0.000  0.000  1.404    6   118  0\n",
              "4598  0.96  0.00    0.00  0.0  0.32  0.00  ...  0.000  0.000  1.147    5    78  0\n",
              "4599  0.00  0.00    0.65  0.0  0.00  0.00  ...  0.000  0.000  1.250    5    40  0\n",
              "\n",
              "[4600 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H3iOTjobifO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the column names\n",
        "spam.columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
        "'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
        "'word_freq_receive','word_freq_will','word_freq_people','word_freq_report','word_freq_addresses',\n",
        "'word_freq_free','word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your',\n",
        "'word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george',\n",
        "'word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data',\n",
        "'word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
        "'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project',\n",
        "'word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(',\n",
        "'char_freq_[','char_freq_exclamation','char_freq_dollar','char_freq_hashtag','capital_run_length_average',\n",
        "'capital_run_length_longest','capital_run_length_total','spam']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ-q3BwUf10x",
        "colab_type": "code",
        "outputId": "463de534-a4ce-4560-a851-0da371ec2b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# previewing the top of the dataset\n",
        "spam.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_exclamation</th>\n",
              "      <th>char_freq_dollar</th>\n",
              "      <th>char_freq_hashtag</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make  word_freq_address  ...  capital_run_length_total  spam\n",
              "0            0.21               0.28  ...                      1028     1\n",
              "1            0.06               0.00  ...                      2259     1\n",
              "2            0.00               0.00  ...                       191     1\n",
              "3            0.00               0.00  ...                       191     1\n",
              "4            0.00               0.00  ...                        54     1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmVkQn2s5afS",
        "colab_type": "code",
        "outputId": "1bf56814-9b8e-4f3d-cc3c-cf03cc2d4972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#previewing the bottom of the dataset\n",
        "spam.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_exclamation</th>\n",
              "      <th>char_freq_dollar</th>\n",
              "      <th>char_freq_hashtag</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word_freq_make  word_freq_address  ...  capital_run_length_total  spam\n",
              "4595            0.31                0.0  ...                        88     0\n",
              "4596            0.00                0.0  ...                        14     0\n",
              "4597            0.30                0.0  ...                       118     0\n",
              "4598            0.96                0.0  ...                        78     0\n",
              "4599            0.00                0.0  ...                        40     0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QgkSkJg6Gsx",
        "colab_type": "code",
        "outputId": "946d58c0-a6f6-4f79-ee7b-a2b5005f9d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# checking the summary statistics of our dataset\n",
        "spam.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_exclamation</th>\n",
              "      <th>char_freq_dollar</th>\n",
              "      <th>char_freq_hashtag</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104576</td>\n",
              "      <td>0.212922</td>\n",
              "      <td>0.280578</td>\n",
              "      <td>0.065439</td>\n",
              "      <td>0.312222</td>\n",
              "      <td>0.095922</td>\n",
              "      <td>0.114233</td>\n",
              "      <td>0.105317</td>\n",
              "      <td>0.090087</td>\n",
              "      <td>0.239465</td>\n",
              "      <td>0.059837</td>\n",
              "      <td>0.541680</td>\n",
              "      <td>0.093950</td>\n",
              "      <td>0.058639</td>\n",
              "      <td>0.049215</td>\n",
              "      <td>0.248833</td>\n",
              "      <td>0.142617</td>\n",
              "      <td>0.184504</td>\n",
              "      <td>1.662041</td>\n",
              "      <td>0.085596</td>\n",
              "      <td>0.809728</td>\n",
              "      <td>0.121228</td>\n",
              "      <td>0.101667</td>\n",
              "      <td>0.094289</td>\n",
              "      <td>0.549624</td>\n",
              "      <td>0.265441</td>\n",
              "      <td>0.767472</td>\n",
              "      <td>0.124872</td>\n",
              "      <td>0.098937</td>\n",
              "      <td>0.102874</td>\n",
              "      <td>0.064767</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.097250</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.105435</td>\n",
              "      <td>0.097498</td>\n",
              "      <td>0.136983</td>\n",
              "      <td>0.013204</td>\n",
              "      <td>0.078646</td>\n",
              "      <td>0.064848</td>\n",
              "      <td>0.043676</td>\n",
              "      <td>0.132367</td>\n",
              "      <td>0.046109</td>\n",
              "      <td>0.079213</td>\n",
              "      <td>0.301289</td>\n",
              "      <td>0.179863</td>\n",
              "      <td>0.005446</td>\n",
              "      <td>0.031876</td>\n",
              "      <td>0.038583</td>\n",
              "      <td>0.139061</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.268960</td>\n",
              "      <td>0.075827</td>\n",
              "      <td>0.044248</td>\n",
              "      <td>5.191827</td>\n",
              "      <td>52.170870</td>\n",
              "      <td>283.290435</td>\n",
              "      <td>0.393913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305387</td>\n",
              "      <td>1.290700</td>\n",
              "      <td>0.504170</td>\n",
              "      <td>1.395303</td>\n",
              "      <td>0.672586</td>\n",
              "      <td>0.273850</td>\n",
              "      <td>0.391480</td>\n",
              "      <td>0.401112</td>\n",
              "      <td>0.278643</td>\n",
              "      <td>0.644816</td>\n",
              "      <td>0.201565</td>\n",
              "      <td>0.861791</td>\n",
              "      <td>0.301065</td>\n",
              "      <td>0.335219</td>\n",
              "      <td>0.258871</td>\n",
              "      <td>0.825881</td>\n",
              "      <td>0.444099</td>\n",
              "      <td>0.530930</td>\n",
              "      <td>1.775669</td>\n",
              "      <td>0.509821</td>\n",
              "      <td>1.200938</td>\n",
              "      <td>1.025866</td>\n",
              "      <td>0.350321</td>\n",
              "      <td>0.442681</td>\n",
              "      <td>1.671511</td>\n",
              "      <td>0.887043</td>\n",
              "      <td>3.367639</td>\n",
              "      <td>0.538631</td>\n",
              "      <td>0.593389</td>\n",
              "      <td>0.456729</td>\n",
              "      <td>0.403435</td>\n",
              "      <td>0.328594</td>\n",
              "      <td>0.555966</td>\n",
              "      <td>0.329480</td>\n",
              "      <td>0.532315</td>\n",
              "      <td>0.402664</td>\n",
              "      <td>0.423493</td>\n",
              "      <td>0.220675</td>\n",
              "      <td>0.434718</td>\n",
              "      <td>0.349953</td>\n",
              "      <td>0.361243</td>\n",
              "      <td>0.766900</td>\n",
              "      <td>0.223835</td>\n",
              "      <td>0.622042</td>\n",
              "      <td>1.011787</td>\n",
              "      <td>0.911214</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>0.285765</td>\n",
              "      <td>0.243497</td>\n",
              "      <td>0.270377</td>\n",
              "      <td>0.109406</td>\n",
              "      <td>0.815726</td>\n",
              "      <td>0.245906</td>\n",
              "      <td>0.429388</td>\n",
              "      <td>31.732891</td>\n",
              "      <td>194.912453</td>\n",
              "      <td>606.413764</td>\n",
              "      <td>0.488669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.310000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.275500</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.640000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314250</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.705250</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>265.250000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>2.610000</td>\n",
              "      <td>9.670000</td>\n",
              "      <td>5.550000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.410000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>5.450000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>20.830000</td>\n",
              "      <td>16.660000</td>\n",
              "      <td>33.330000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.690000</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>8.330000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>3.570000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.420000</td>\n",
              "      <td>22.050000</td>\n",
              "      <td>2.170000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word_freq_make  word_freq_address  ...  capital_run_length_total         spam\n",
              "count     4600.000000        4600.000000  ...               4600.000000  4600.000000\n",
              "mean         0.104576           0.212922  ...                283.290435     0.393913\n",
              "std          0.305387           1.290700  ...                606.413764     0.488669\n",
              "min          0.000000           0.000000  ...                  1.000000     0.000000\n",
              "25%          0.000000           0.000000  ...                 35.000000     0.000000\n",
              "50%          0.000000           0.000000  ...                 95.000000     0.000000\n",
              "75%          0.000000           0.000000  ...                265.250000     1.000000\n",
              "max          4.540000          14.280000  ...              15841.000000     1.000000\n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPLltUoN6bJf",
        "colab_type": "text"
      },
      "source": [
        "The dataset has too many columns to analyse manually.\n",
        "we really need reduction methods here to find the most important features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qXbIh956Ppl",
        "colab_type": "code",
        "outputId": "6eb40862-1cda-4e47-e7fc-9fe734f6cee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# checking summary information about our dataset\n",
        "spam.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4600 entries, 0 to 4599\n",
            "Data columns (total 58 columns):\n",
            "word_freq_make                4600 non-null float64\n",
            "word_freq_address             4600 non-null float64\n",
            "word_freq_all                 4600 non-null float64\n",
            "word_freq_3d                  4600 non-null float64\n",
            "word_freq_our                 4600 non-null float64\n",
            "word_freq_over                4600 non-null float64\n",
            "word_freq_remove              4600 non-null float64\n",
            "word_freq_internet            4600 non-null float64\n",
            "word_freq_order               4600 non-null float64\n",
            "word_freq_mail                4600 non-null float64\n",
            "word_freq_receive             4600 non-null float64\n",
            "word_freq_will                4600 non-null float64\n",
            "word_freq_people              4600 non-null float64\n",
            "word_freq_report              4600 non-null float64\n",
            "word_freq_addresses           4600 non-null float64\n",
            "word_freq_free                4600 non-null float64\n",
            "word_freq_business            4600 non-null float64\n",
            "word_freq_email               4600 non-null float64\n",
            "word_freq_you                 4600 non-null float64\n",
            "word_freq_credit              4600 non-null float64\n",
            "word_freq_your                4600 non-null float64\n",
            "word_freq_font                4600 non-null float64\n",
            "word_freq_000                 4600 non-null float64\n",
            "word_freq_money               4600 non-null float64\n",
            "word_freq_hp                  4600 non-null float64\n",
            "word_freq_hpl                 4600 non-null float64\n",
            "word_freq_george              4600 non-null float64\n",
            "word_freq_650                 4600 non-null float64\n",
            "word_freq_lab                 4600 non-null float64\n",
            "word_freq_labs                4600 non-null float64\n",
            "word_freq_telnet              4600 non-null float64\n",
            "word_freq_857                 4600 non-null float64\n",
            "word_freq_data                4600 non-null float64\n",
            "word_freq_415                 4600 non-null float64\n",
            "word_freq_85                  4600 non-null float64\n",
            "word_freq_technology          4600 non-null float64\n",
            "word_freq_1999                4600 non-null float64\n",
            "word_freq_parts               4600 non-null float64\n",
            "word_freq_pm                  4600 non-null float64\n",
            "word_freq_direct              4600 non-null float64\n",
            "word_freq_cs                  4600 non-null float64\n",
            "word_freq_meeting             4600 non-null float64\n",
            "word_freq_original            4600 non-null float64\n",
            "word_freq_project             4600 non-null float64\n",
            "word_freq_re                  4600 non-null float64\n",
            "word_freq_edu                 4600 non-null float64\n",
            "word_freq_table               4600 non-null float64\n",
            "word_freq_conference          4600 non-null float64\n",
            "char_freq_;                   4600 non-null float64\n",
            "char_freq_(                   4600 non-null float64\n",
            "char_freq_[                   4600 non-null float64\n",
            "char_freq_exclamation         4600 non-null float64\n",
            "char_freq_dollar              4600 non-null float64\n",
            "char_freq_hashtag             4600 non-null float64\n",
            "capital_run_length_average    4600 non-null float64\n",
            "capital_run_length_longest    4600 non-null int64\n",
            "capital_run_length_total      4600 non-null int64\n",
            "spam                          4600 non-null int64\n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMC9cTYn6r7_",
        "colab_type": "code",
        "outputId": "c296acc3-ea6d-4688-83ad-3cf447b41677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spam.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4600, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJjXbgW6yho",
        "colab_type": "code",
        "outputId": "7c3ad50f-1b87-48ba-c13f-6c0273fb1fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "spam.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "word_freq_make                0\n",
              "word_freq_address             0\n",
              "word_freq_all                 0\n",
              "word_freq_3d                  0\n",
              "word_freq_our                 0\n",
              "word_freq_over                0\n",
              "word_freq_remove              0\n",
              "word_freq_internet            0\n",
              "word_freq_order               0\n",
              "word_freq_mail                0\n",
              "word_freq_receive             0\n",
              "word_freq_will                0\n",
              "word_freq_people              0\n",
              "word_freq_report              0\n",
              "word_freq_addresses           0\n",
              "word_freq_free                0\n",
              "word_freq_business            0\n",
              "word_freq_email               0\n",
              "word_freq_you                 0\n",
              "word_freq_credit              0\n",
              "word_freq_your                0\n",
              "word_freq_font                0\n",
              "word_freq_000                 0\n",
              "word_freq_money               0\n",
              "word_freq_hp                  0\n",
              "word_freq_hpl                 0\n",
              "word_freq_george              0\n",
              "word_freq_650                 0\n",
              "word_freq_lab                 0\n",
              "word_freq_labs                0\n",
              "word_freq_telnet              0\n",
              "word_freq_857                 0\n",
              "word_freq_data                0\n",
              "word_freq_415                 0\n",
              "word_freq_85                  0\n",
              "word_freq_technology          0\n",
              "word_freq_1999                0\n",
              "word_freq_parts               0\n",
              "word_freq_pm                  0\n",
              "word_freq_direct              0\n",
              "word_freq_cs                  0\n",
              "word_freq_meeting             0\n",
              "word_freq_original            0\n",
              "word_freq_project             0\n",
              "word_freq_re                  0\n",
              "word_freq_edu                 0\n",
              "word_freq_table               0\n",
              "word_freq_conference          0\n",
              "char_freq_;                   0\n",
              "char_freq_(                   0\n",
              "char_freq_[                   0\n",
              "char_freq_exclamation         0\n",
              "char_freq_dollar              0\n",
              "char_freq_hashtag             0\n",
              "capital_run_length_average    0\n",
              "capital_run_length_longest    0\n",
              "capital_run_length_total      0\n",
              "spam                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-fn2-yr6mUD",
        "colab_type": "text"
      },
      "source": [
        "* The data has 4600 rows and 58 columns\n",
        "* We have no missing values\n",
        "* The columns are too many and we need to used reduction methods to reduce the data dimension.\n",
        "* We will go straight to modelling since even making charts can't help in analysing the columns.\n",
        "* We will plot the target variable though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC1tDjz26nby",
        "colab_type": "code",
        "outputId": "78d55425-942c-46c5-e6c7-a2d056c99103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# Plotting the target variable \n",
        "# using seaborn\n",
        "\n",
        "sns.countplot(spam.spam)\n",
        "plt.title('Spam vs Non_Spam Emails')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlZNMJgAfSx0",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Naives Bayes Classifier\n",
        "Perform classification of the testing set samples using the Naive Bayes Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEAj4sEZ7iBB",
        "colab_type": "text"
      },
      "source": [
        "* The Naive Bayes Classifier is a statistical classification technique based on the Bayes Theorem. \n",
        "\n",
        "* It has high accuracy and speed on large datasets.\n",
        "\n",
        "* This type of classifier takes into account the assumption that the effect of a particular feature in a class is independent of other features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVg0XobB7FOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create correlation matrix\n",
        "corr_matrix = spam.corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Find index of feature columns with correlation greater than 0.95\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "\n",
        "# Drop the highly correlated features \n",
        "spam.drop(spam[to_drop], axis=1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnYxdU8N7_F-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8da4793-2134-4d1e-b2eb-401f2aef0791"
      },
      "source": [
        "# checking if there are any correlated features\n",
        "to_drop"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['word_freq_415']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8S-gVZP8M26",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "No columns were dropped since there are no correlated features. we will use PCA and LDA to reduce the data dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH-ZNorz8QkO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Splitting the Spam data into 80, 20 train and test sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpV_A6NA7_D1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "bf16f1be-fd48-4b6d-88d6-9db67e9b6b85"
      },
      "source": [
        "# Fitting the Naives Bayes Classifier: GausssianNB since the features are continuous\n",
        "# Splitting the data\n",
        "\n",
        "X = spam.iloc[:, 0:-1]\n",
        "y = spam.iloc[:,-1]\n",
        "\n",
        "# transform = Normalizer()\n",
        "# X = transform.transform(X)\n",
        "\n",
        "# X = normalize(X, norm = 'l2')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "sc = StandardScaler(with_std = False, with_mean = False)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# pca = PCA(n_components = 1)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_test = pca.transform(X_test)\n",
        "\n",
        "lda = LDA(n_components=10)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "model = gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating our model using accuracy score, confusion matrix and classification report.\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9032608695652173\n",
            "\n",
            "\n",
            "[[513  25]\n",
            " [ 64 318]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       538\n",
            "           1       0.93      0.83      0.88       382\n",
            "\n",
            "    accuracy                           0.90       920\n",
            "   macro avg       0.91      0.89      0.90       920\n",
            "weighted avg       0.90      0.90      0.90       920\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(56, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOWzZCFa8jRH",
        "colab_type": "text"
      },
      "source": [
        "* The 80,20 split model yielded 90.3% accuracy.\n",
        "* Interpreting the confusion matrix;\n",
        "* The first row is about the non-spam-predictions:\n",
        "     * 513 emails were correctly classified as Ham (called true negatives) \n",
        "     * 25 were wrongly classified as ham (false positives).\n",
        "* The second row is about the spam-predictions: \n",
        "     * 64 emails where wrongly classified as spam (false negatives) and\n",
        "     * 318 were correctly classified as Spam (true positives).\n",
        "     \n",
        "* In this classification we value the Recall so much. \n",
        "* The Recall is 95% which means that this is good model.\n",
        "* Recall is the ability of a model to find all the relevant cases within a dataset.\n",
        "* It is also called sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1nxr_-e7-_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "1cb363b8-d20c-4ebf-dc72-faf477b637c4"
      },
      "source": [
        "# Fitting the Naives Bayes Classifier: GausssianNB since the features are continuous\n",
        "# Splitting the data\n",
        "\n",
        "X = spam.iloc[:, 0:-1]\n",
        "y = spam.iloc[:,-1]\n",
        "\n",
        "# transform = Normalizer()\n",
        "# X = transform.transform(X)\n",
        "\n",
        "# X = normalize(X, norm = 'l2')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "sc = StandardScaler(with_std = False, with_mean = False)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# pca = PCA(n_components = 1)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_test = pca.transform(X_test)\n",
        "\n",
        "lda = LDA(n_components=10)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "model = gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating our model using accuracy score, confusion matrix and classification report.\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9036231884057971\n",
            "\n",
            "\n",
            "[[789  33]\n",
            " [100 458]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       822\n",
            "           1       0.93      0.82      0.87       558\n",
            "\n",
            "    accuracy                           0.90      1380\n",
            "   macro avg       0.91      0.89      0.90      1380\n",
            "weighted avg       0.91      0.90      0.90      1380\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(56, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDVUhYYp8wBZ",
        "colab_type": "text"
      },
      "source": [
        "* The 70,30 split model also yielded 90.3% accuracy.\n",
        "* Interpreting the confusion matrix;\n",
        "* The first row is about the non-spam-predictions:\n",
        "     * 789 emails were correctly classified as Ham (called true negatives) \n",
        "     * 33 were wrongly classified as ham (false positives).\n",
        "* The second row is about the spam-predictions: \n",
        "     * 100 emails where wrongly classified as spam (false negatives) and\n",
        "     * 458 were correctly classified as Spam (true positives).\n",
        "     \n",
        "* The recall improved slightly from 95% in the previous model to 96%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yq8zRIg7-9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "d1eb232e-abc9-44b2-86af-ad6fead30b5b"
      },
      "source": [
        "# Fitting the Naives Bayes Classifier: GausssianNB since the features are continuous\n",
        "# Splitting the data\n",
        "\n",
        "X = spam.iloc[:, 0:-1]\n",
        "y = spam.iloc[:,-1]\n",
        "\n",
        "# transform = Normalizer()\n",
        "# X = transform.transform(X)\n",
        "\n",
        "# X = normalize(X, norm = 'l2')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, random_state = 0)\n",
        "\n",
        "sc = StandardScaler(with_std = False, with_mean = False)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# pca = PCA(n_components = 1)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_test = pca.transform(X_test)\n",
        "\n",
        "lda = LDA(n_components=10)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "model = gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating our model using accuracy score, confusion matrix and classification report.\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9081521739130435\n",
            "\n",
            "\n",
            "[[1060   37]\n",
            " [ 132  611]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93      1097\n",
            "           1       0.94      0.82      0.88       743\n",
            "\n",
            "    accuracy                           0.91      1840\n",
            "   macro avg       0.92      0.89      0.90      1840\n",
            "weighted avg       0.91      0.91      0.91      1840\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(56, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHiyN4k9872D",
        "colab_type": "text"
      },
      "source": [
        "* The 60,40 split model yielded 90.8% accuracy\n",
        "* This is a slight improvement compared to the previous split models.\n",
        "* Interpreting the confusion matrix;\n",
        "* The first row is about the non-spam-predictions:\n",
        "     * 1060 emails were correctly classified as Ham (called true negatives) \n",
        "     * 37 were wrongly classified as ham (false positives).\n",
        "* The second row is about the spam-predictions: \n",
        "     * 132 emails where wrongly classified as spam (false negatives) and\n",
        "     * 611 were correctly classified as Spam (true positives)..\n",
        "     \n",
        "* Again here the recall increased to 97%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucen1QB69HIR",
        "colab_type": "text"
      },
      "source": [
        "### <font color = cyan> Optimizing Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EiygfLk9EKu",
        "colab_type": "text"
      },
      "source": [
        "Improving the performance of the Naive Bayes classifier:\n",
        " * Normalizing our data\n",
        " * Remove Redundant/ correlated features\n",
        " * Apply smoothing techniques; If our dataset has zero frequency issue, we can apply smoothing techniques such as \"Laplace Correction\" to predict the class of the test data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkSosI319Y7w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We have already applied the first techniques in our models which was relevant in this scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngDLFwO-Yd9",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Challenging the Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrlsUrEn-jxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "3f7be4f6-b2dd-4500-899c-2e9e7d072098"
      },
      "source": [
        "# Fitting the Support Vector Classifier\n",
        "# Splitting the data\n",
        "\n",
        "X = spam.iloc[:, 0:-1]\n",
        "y = spam.iloc[:,-1]\n",
        "\n",
        "# transform = Normalizer()\n",
        "# X = transform.transform(X)\n",
        "\n",
        "# X = normalize(X, norm = 'l2')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, random_state = 0)\n",
        "\n",
        "sc = StandardScaler(with_std = False, with_mean = False)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# pca = PCA(n_components = 1)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_test = pca.transform(X_test)\n",
        "\n",
        "lda = LDA(n_components=10)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "svc = SVC(C=0.1, gamma=0.001, kernel = 'linear')\n",
        "\n",
        "model = svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating our model using accuracy score, confusion matrix and classification report.\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9228260869565217\n",
            "\n",
            "\n",
            "[[1043   54]\n",
            " [  88  655]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94      1097\n",
            "           1       0.92      0.88      0.90       743\n",
            "\n",
            "    accuracy                           0.92      1840\n",
            "   macro avg       0.92      0.92      0.92      1840\n",
            "weighted avg       0.92      0.92      0.92      1840\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(56, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttpz1-TZ-tK6",
        "colab_type": "text"
      },
      "source": [
        "* The Support Vector Machine model yielded 92.2% accuracy.\n",
        "* This is a great improvement compared to the Naive Bayes Gaussian models.\n",
        "* Interpreting the confusion matrix;\n",
        "* The first row is about the non-spam-predictions:\n",
        "     * 10 emails were correctly classified as Ham (called true negatives) \n",
        "     * 54 were wrongly classified as ham (false positives).\n",
        "* The second row is about the spam-predictions: \n",
        "     * 88 emails where wrongly classified as spam (false negatives) and\n",
        "     * 655 were correctly classified as Spam (true positives)..\n",
        "     \n",
        "* Again here the recall increased to 95%.\n",
        "* This is slight reduction.\n",
        "* Though the accuracy improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RMigiz2fX3B",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EwDVw-o9bEn",
        "colab_type": "text"
      },
      "source": [
        "* Normalizing or standardizing the features works greatly to improve the classifier.\n",
        "* For the spam detection challenge project, using the Standard Scaler yielded the best results.\n",
        "* Also, using the linear discriminant analysis for dimension reduction yields beter results compared to PCA.\n",
        "* Lastly increasing the test size in the spam dataset imporved both the accuracy and the Recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEJEVFt2-7Wk",
        "colab_type": "text"
      },
      "source": [
        "## <font color = red> Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4FqRK_w-6N2",
        "colab_type": "text"
      },
      "source": [
        "* The Gaussian NB is the best model since it yielded both the best Accuracy and Recall scores.\n",
        "* Optimizing the model is very essential:\n",
        "    1. Scaling or normalizing the features\n",
        "    2. Reducing the data dimensions\n",
        "    3. Increasing the test size for a large dataset."
      ]
    }
  ]
}